{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb35193",
   "metadata": {},
   "source": [
    "# Setup Database e Tabelas - MKL Bank\n",
    "\n",
    "Este notebook cria o database, schema e todas as tabelas necess√°rias para o sistema banc√°rio MKL baseado nos schemas dos arquivos CSV da pasta `sample_sintetic_data`.\n",
    "\n",
    "## Objetivo\n",
    "- Criar o database FSI (Financial Services Industry)\n",
    "- Criar o schema de destino\n",
    "- Analisar os arquivos CSV para definir estruturas de tabelas\n",
    "- Criar todas as tabelas com os tipos de dados apropriados\n",
    "- Verificar a cria√ß√£o das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad99176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Configuration Setup\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    'port': os.getenv(\"PGPORT\", \"5432\"),\n",
    "    'user': os.getenv(\"PGUSER\", \"postgres\"),\n",
    "    'password': os.getenv(\"PGPASSWORD\", \"postgres\"),\n",
    "    'database': os.getenv(\"PGDATABASE\", \"postgres\")  # Default database to connect initially\n",
    "}\n",
    "\n",
    "TARGETSCHEMA = os.getenv(\"TARGETSCHEMA\", \"public\")\n",
    "TARGET_DB = os.getenv(\"PGDATABASE\", \"fsi_db\")\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "DATA_PATH = \"../assets/sample_sintetic_data/\"\n",
    "\n",
    "print(f\"üîß Configura√ß√£o do Database:\")\n",
    "print(f\"   Host: {DB_CONFIG['host']}\")\n",
    "print(f\"   Port: {DB_CONFIG['port']}\")\n",
    "print(f\"   User: {DB_CONFIG['user']}\")\n",
    "print(f\"   Target Database: {TARGET_DB}\")\n",
    "print(f\"   Target Schema: {TARGETSCHEMA}\")\n",
    "print(f\"   Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Connection Functions\n",
    "def get_default_connection():\n",
    "    \"\"\"Conecta ao database padr√£o para opera√ß√µes administrativas\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao conectar ao database padr√£o: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_target_connection():\n",
    "    \"\"\"Conecta ao database de destino\"\"\"\n",
    "    try:\n",
    "        target_config = DB_CONFIG.copy()\n",
    "        target_config['database'] = TARGET_DB\n",
    "        conn = psycopg2.connect(**target_config)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao conectar ao database de destino: {e}\")\n",
    "        raise\n",
    "\n",
    "def execute_sql(connection, sql, fetch=False):\n",
    "    \"\"\"Executa SQL e retorna resultado se necess√°rio\"\"\"\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        if fetch:\n",
    "            result = cursor.fetchall()\n",
    "            cursor.close()\n",
    "            return result\n",
    "        else:\n",
    "            connection.commit()\n",
    "            cursor.close()\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao executar SQL: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de conex√£o definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c624b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Target Database\n",
    "def create_database():\n",
    "    \"\"\"Cria o database de destino se n√£o existir\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Verificando se database '{TARGET_DB}' existe...\")\n",
    "        \n",
    "        # Conecta ao database padr√£o\n",
    "        conn = get_default_connection()\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        \n",
    "        # Verifica se o database j√° existe\n",
    "        check_db_sql = \"SELECT 1 FROM pg_catalog.pg_database WHERE datname = %s\"\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(check_db_sql, (TARGET_DB,))\n",
    "        exists = cursor.fetchone()\n",
    "        \n",
    "        if not exists:\n",
    "            # Cria o database\n",
    "            create_db_sql = f'CREATE DATABASE \"{TARGET_DB}\"'\n",
    "            cursor.execute(create_db_sql)\n",
    "            logger.info(f\"‚úÖ Database '{TARGET_DB}' criado com sucesso!\")\n",
    "        else:\n",
    "            logger.info(f\"‚ÑπÔ∏è Database '{TARGET_DB}' j√° existe.\")\n",
    "            \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao criar database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Executar cria√ß√£o do database\n",
    "create_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa61979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Schema\n",
    "def create_schema():\n",
    "    \"\"\"Cria o schema de destino se n√£o existir\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Criando schema '{TARGETSCHEMA}' no database '{TARGET_DB}'...\")\n",
    "        \n",
    "        conn = get_target_connection()\n",
    "        \n",
    "        # Cria o schema\n",
    "        create_schema_sql = f'CREATE SCHEMA IF NOT EXISTS \"{TARGETSCHEMA}\"'\n",
    "        execute_sql(conn, create_schema_sql)\n",
    "        \n",
    "        logger.info(f\"‚úÖ Schema '{TARGETSCHEMA}' criado/verificado com sucesso!\")\n",
    "        \n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao criar schema: {e}\")\n",
    "        raise\n",
    "\n",
    "# Executar cria√ß√£o do schema\n",
    "create_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CSV File Schemas\n",
    "def analyze_csv_files():\n",
    "    \"\"\"Analisa os arquivos CSV para determinar os schemas das tabelas\"\"\"\n",
    "    \n",
    "    csv_files = [\n",
    "        'agencias.csv',\n",
    "        'clientes.csv', \n",
    "        'contas.csv',\n",
    "        'cartoes.csv',\n",
    "        'chaves_pix.csv',\n",
    "        'transacoes.csv'\n",
    "    ]\n",
    "    \n",
    "    schemas = {}\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            file_path = os.path.join(DATA_PATH, csv_file)\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                logger.warning(f\"‚ö†Ô∏è Arquivo n√£o encontrado: {file_path}\")\n",
    "                continue\n",
    "                \n",
    "            # L√™ uma amostra do arquivo para an√°lise\n",
    "            df = pd.read_csv(file_path, nrows=100)\n",
    "            table_name = csv_file.replace('.csv', '')\n",
    "            \n",
    "            logger.info(f\"üìä Analisando {csv_file} ({len(df)} amostras)\")\n",
    "            print(f\"\\nTabela: {table_name}\")\n",
    "            print(f\"Colunas: {list(df.columns)}\")\n",
    "            \n",
    "            # Analisa tipos de dados\n",
    "            column_types = {}\n",
    "            for col in df.columns:\n",
    "                col_data = df[col].dropna()\n",
    "                \n",
    "                if col_data.empty:\n",
    "                    column_types[col] = \"TEXT\"\n",
    "                    continue\n",
    "                \n",
    "                # Determina tipo baseado no conte√∫do e nome da coluna\n",
    "                if col in ['id_cliente', 'codigo_agencia', 'id_conta', 'cartao_id', 'agencia_id']:\n",
    "                    column_types[col] = \"BIGINT\"\n",
    "                elif col in ['chave_pix_id']:\n",
    "                    column_types[col] = \"SERIAL\"\n",
    "                elif 'id' in col.lower() and 'transacao' in col.lower():\n",
    "                    column_types[col] = \"VARCHAR(30)\"\n",
    "                elif 'data_' in col or 'created_at' in col:\n",
    "                    column_types[col] = \"TIMESTAMP\"\n",
    "                elif col in ['saldo', 'valor', 'limite_credito', 'limite']:\n",
    "                    column_types[col] = \"DECIMAL(15,2)\"\n",
    "                elif col in ['cpf']:\n",
    "                    column_types[col] = \"VARCHAR(14)\"\n",
    "                elif col in ['numero_cartao']:\n",
    "                    column_types[col] = \"VARCHAR(16)\"\n",
    "                elif col in ['codigo_barras', 'codigo_boleto']:\n",
    "                    column_types[col] = \"VARCHAR(100)\"\n",
    "                elif col in ['telefone']:\n",
    "                    column_types[col] = \"VARCHAR(20)\"\n",
    "                elif col in ['email']:\n",
    "                    column_types[col] = \"VARCHAR(200)\"\n",
    "                elif col in ['nome', 'nome_agencia', 'estabelecimento', 'beneficiario', 'depositante']:\n",
    "                    column_types[col] = \"VARCHAR(200)\"\n",
    "                elif col in ['endereco', 'descricao']:\n",
    "                    column_types[col] = \"TEXT\"\n",
    "                elif col in ['cidade']:\n",
    "                    column_types[col] = \"VARCHAR(100)\"\n",
    "                elif col in ['estado']:\n",
    "                    column_types[col] = \"CHAR(2)\"\n",
    "                elif col in ['cep']:\n",
    "                    column_types[col] = \"VARCHAR(10)\"\n",
    "                elif col in ['status', 'tipo', 'genero']:\n",
    "                    column_types[col] = \"CHAR(1)\"\n",
    "                elif col in ['tipo_cartao', 'tipo_chave', 'tipo_transferencia', 'tipo_deposito', 'categoria', 'operacao']:\n",
    "                    column_types[col] = \"VARCHAR(50)\"\n",
    "                elif col in ['chave_pix', 'chave_pix_destino', 'chave_pix_origem', 'valor_chave']:\n",
    "                    column_types[col] = \"VARCHAR(200)\"\n",
    "                else:\n",
    "                    # An√°lise autom√°tica para outros campos\n",
    "                    sample_val = str(col_data.iloc[0]) if len(col_data) > 0 else \"\"\n",
    "                    if len(sample_val) > 100:\n",
    "                        column_types[col] = \"TEXT\"\n",
    "                    elif len(sample_val) > 50:\n",
    "                        column_types[col] = \"VARCHAR(200)\"\n",
    "                    else:\n",
    "                        column_types[col] = \"VARCHAR(100)\"\n",
    "            \n",
    "            schemas[table_name] = {\n",
    "                'columns': column_types,\n",
    "                'sample_data': df.head(3)\n",
    "            }\n",
    "            \n",
    "            print(f\"Schema definido: {column_types}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erro ao analisar {csv_file}: {e}\")\n",
    "    \n",
    "    return schemas\n",
    "\n",
    "# Executar an√°lise\n",
    "table_schemas = analyze_csv_files()\n",
    "print(f\"\\n‚úÖ An√°lise conclu√≠da! {len(table_schemas)} tabelas analisadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Table Creation Scripts\n",
    "def generate_create_table_scripts(schemas):\n",
    "    \"\"\"Gera scripts SQL para cria√ß√£o das tabelas\"\"\"\n",
    "    \n",
    "    create_scripts = {}\n",
    "    \n",
    "    # Ordem de cria√ß√£o (tabelas com FK devem vir depois)\n",
    "    table_order = ['agencias', 'clientes', 'contas', 'cartoes', 'chaves_pix', 'transacoes']\n",
    "    \n",
    "    for table_name in table_order:\n",
    "        if table_name not in schemas:\n",
    "            continue\n",
    "            \n",
    "        columns = schemas[table_name]['columns']\n",
    "        \n",
    "        # Monta o script CREATE TABLE\n",
    "        script_lines = [f'CREATE TABLE IF NOT EXISTS \"{TARGETSCHEMA}\".{table_name} (']\n",
    "        \n",
    "        column_definitions = []\n",
    "        \n",
    "        for col_name, col_type in columns.items():\n",
    "            definition = f'    \"{col_name}\" {col_type}'\n",
    "            \n",
    "            # Adiciona constraints\n",
    "            if col_name in ['id_cliente', 'codigo_agencia', 'id_conta', 'numero_cartao', 'id_transacao', 'chave_pix_id']:\n",
    "                definition += ' PRIMARY KEY'\n",
    "            elif col_name == 'cpf':\n",
    "                definition += ' UNIQUE NOT NULL'\n",
    "            elif 'id' in col_name.lower() and col_name != 'chave_pix_id':\n",
    "                definition += ' NOT NULL'\n",
    "            elif col_name in ['nome', 'chave_pix']:\n",
    "                definition += ' NOT NULL'\n",
    "                \n",
    "            column_definitions.append(definition)\n",
    "        \n",
    "        # Adiciona foreign keys\n",
    "        if table_name == 'contas':\n",
    "            column_definitions.append(f'    FOREIGN KEY (\"codigo_agencia\") REFERENCES \"{TARGETSCHEMA}\".agencias(\"codigo_agencia\")')\n",
    "            column_definitions.append(f'    FOREIGN KEY (\"id_cliente\") REFERENCES \"{TARGETSCHEMA}\".clientes(\"id_cliente\")')\n",
    "        elif table_name == 'cartoes':\n",
    "            column_definitions.append(f'    FOREIGN KEY (\"id_cliente\") REFERENCES \"{TARGETSCHEMA}\".clientes(\"id_cliente\")')\n",
    "        elif table_name == 'chaves_pix':\n",
    "            column_definitions.append(f'    FOREIGN KEY (\"id_cliente\") REFERENCES \"{TARGETSCHEMA}\".clientes(\"id_cliente\")')\n",
    "        elif table_name == 'transacoes':\n",
    "            column_definitions.append(f'    FOREIGN KEY (\"id_conta\") REFERENCES \"{TARGETSCHEMA}\".contas(\"id_conta\")')\n",
    "        \n",
    "        script_lines.append(',\\n'.join(column_definitions))\n",
    "        script_lines.append(');')\n",
    "        \n",
    "        create_scripts[table_name] = '\\n'.join(script_lines)\n",
    "        \n",
    "        logger.info(f\"üìù Script gerado para tabela: {table_name}\")\n",
    "    \n",
    "    return create_scripts\n",
    "\n",
    "# Gerar scripts\n",
    "table_scripts = generate_create_table_scripts(table_schemas)\n",
    "\n",
    "# Exibir scripts gerados\n",
    "print(\"üìã Scripts de cria√ß√£o de tabelas:\")\n",
    "print(\"=\" * 60)\n",
    "for table_name, script in table_scripts.items():\n",
    "    print(f\"\\n-- Tabela: {table_name}\")\n",
    "    print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff881b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Database Schema and Tables\n",
    "def create_tables(scripts):\n",
    "    \"\"\"Executa os scripts de cria√ß√£o das tabelas\"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = get_target_connection()\n",
    "        \n",
    "        logger.info(\"üöÄ Iniciando cria√ß√£o das tabelas...\")\n",
    "        \n",
    "        # Ordem de cria√ß√£o\n",
    "        table_order = ['agencias', 'clientes', 'contas', 'cartoes', 'chaves_pix', 'transacoes']\n",
    "        \n",
    "        for table_name in table_order:\n",
    "            if table_name in scripts:\n",
    "                logger.info(f\"üìù Criando tabela: {table_name}\")\n",
    "                \n",
    "                try:\n",
    "                    execute_sql(conn, scripts[table_name])\n",
    "                    logger.info(f\"‚úÖ Tabela '{table_name}' criada com sucesso!\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"‚ùå Erro ao criar tabela '{table_name}': {e}\")\n",
    "                    raise\n",
    "        \n",
    "        conn.close()\n",
    "        logger.info(\"üéâ Todas as tabelas foram criadas com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro na cria√ß√£o das tabelas: {e}\")\n",
    "        raise\n",
    "\n",
    "# Executar cria√ß√£o das tabelas\n",
    "create_tables(table_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Table Creation\n",
    "def verify_tables():\n",
    "    \"\"\"Verifica se todas as tabelas foram criadas corretamente\"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = get_target_connection()\n",
    "        \n",
    "        # Lista todas as tabelas no schema\n",
    "        list_tables_sql = \"\"\"\n",
    "            SELECT table_name, table_type\n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = %s\n",
    "            ORDER BY table_name\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(list_tables_sql, (TARGETSCHEMA,))\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\nüîç VERIFICA√á√ÉO DE TABELAS NO SCHEMA '{TARGETSCHEMA}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if tables:\n",
    "            print(f\"üìä Total de tabelas encontradas: {len(tables)}\")\n",
    "            print(\"\\nTabelas criadas:\")\n",
    "            \n",
    "            for table_name, table_type in tables:\n",
    "                print(f\"‚úÖ {table_name} ({table_type})\")\n",
    "                \n",
    "                # Verifica colunas de cada tabela\n",
    "                columns_sql = \"\"\"\n",
    "                    SELECT column_name, data_type, is_nullable, column_default\n",
    "                    FROM information_schema.columns \n",
    "                    WHERE table_schema = %s AND table_name = %s\n",
    "                    ORDER BY ordinal_position\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(columns_sql, (TARGETSCHEMA, table_name))\n",
    "                columns = cursor.fetchall()\n",
    "                \n",
    "                print(f\"   üìã Colunas ({len(columns)}):\")\n",
    "                for col_name, data_type, nullable, default in columns:\n",
    "                    null_info = \"NULL\" if nullable == \"YES\" else \"NOT NULL\"\n",
    "                    default_info = f\", DEFAULT: {default}\" if default else \"\"\n",
    "                    print(f\"      ‚Ä¢ {col_name}: {data_type} ({null_info}{default_info})\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nenhuma tabela encontrada!\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return len(tables)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro na verifica√ß√£o das tabelas: {e}\")\n",
    "        raise\n",
    "\n",
    "# Executar verifica√ß√£o\n",
    "table_count = verify_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df090d80",
   "metadata": {},
   "source": [
    "## ‚úÖ Setup Conclu√≠do com Sucesso!\n",
    "\n",
    "### üìä Resumo da Execu√ß√£o:\n",
    "- **Database:** `{TARGET_DB}` criado/verificado\n",
    "- **Schema:** `{TARGETSCHEMA}` criado/verificado  \n",
    "- **Tabelas:** {table_count} tabelas criadas com sucesso\n",
    "\n",
    "### üóÇÔ∏è Estrutura Criada:\n",
    "1. **agencias** - Dados das ag√™ncias banc√°rias\n",
    "2. **clientes** - Informa√ß√µes dos clientes\n",
    "3. **contas** - Contas banc√°rias dos clientes\n",
    "4. **cartoes** - Cart√µes de d√©bito/cr√©dito\n",
    "5. **chaves_pix** - Chaves PIX cadastradas\n",
    "6. **transacoes** - Transa√ß√µes financeiras\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos:\n",
    "1. **Execute o notebook:** `02_insert_main_data.ipynb` para inserir os dados principais\n",
    "2. **Execute o notebook:** `03_insert_movement_data.ipynb` para inserir os dados de movimenta√ß√µes\n",
    "\n",
    "### üìã Observa√ß√µes:\n",
    "- Todas as tabelas foram criadas com relacionamentos (Foreign Keys)\n",
    "- Os tipos de dados foram definidos com base na an√°lise dos CSVs\n",
    "- Primary Keys e constraints foram aplicadas adequadamente\n",
    "- O sistema est√° pronto para receber os dados!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
