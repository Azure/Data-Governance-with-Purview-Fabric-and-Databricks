{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b16a13",
   "metadata": {},
   "source": [
    "# Inser√ß√£o de Dados Principais - MKL Bank\n",
    "\n",
    "Este notebook insere os dados principais do sistema banc√°rio: ag√™ncias, clientes, contas, cart√µes, chaves PIX e transa√ß√µes.\n",
    "\n",
    "## Objetivo\n",
    "- Carregar e inserir dados das tabelas principais\n",
    "- Validar integridade referencial\n",
    "- Verificar inser√ß√£o dos dados\n",
    "- Preparar sistema para dados de movimenta√ß√µes\n",
    "\n",
    "## Tabelas Processadas:\n",
    "1. **agencias** - Ag√™ncias banc√°rias\n",
    "2. **clientes** - Clientes do banco\n",
    "3. **contas** - Contas banc√°rias\n",
    "4. **cartoes** - Cart√µes de d√©bito/cr√©dito\n",
    "5. **chaves_pix** - Chaves PIX\n",
    "6. **transacoes** - Transa√ß√µes financeiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9c76db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv \n",
    "import warnings\n",
    "# Carregar vari√°veis do arquivo .env de um diret√≥rio espec√≠fico\n",
    "env_path = \"../env_files/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5105fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configura√ß√£o:\n",
      "   Database: mkl_bank\n",
      "   Schema: core_bank\n",
      "   Data Path: ../assets/sample_sintetic_data/\n"
     ]
    }
   ],
   "source": [
    "# Database Configuration - Alinhado com o notebook 01\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    'port': int(os.getenv(\"PGPORT\", \"5432\")),  # Converter para int\n",
    "    'user': os.getenv(\"PGUSER\", \"postgres\"),\n",
    "    'password': os.getenv(\"PGPASSWORD\", \"postgres\"),\n",
    "    'database': os.getenv(\"PGDATABASE\", \"mkl_bank\"),  # Target database correto\n",
    "    'sslmode': os.getenv(\"PGSSLMODE\", \"require\"),\n",
    "    'connect_timeout': 30,\n",
    "    'application_name': 'MKL-Bank-DataInsert'\n",
    "}\n",
    "\n",
    "TARGETSCHEMA = os.getenv(\"TARGETSCHEMA\", \"core_bank\")  # Schema correto\n",
    "TARGET_DB = os.getenv(\"PGDATABASE\", \"mkl_bank\")  # Database correto\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "DATA_PATH = \"../assets/sample_sintetic_data/\"\n",
    "\n",
    "print(f\"üîß Configura√ß√£o:\")\n",
    "print(f\"   Database: {TARGET_DB}\")\n",
    "print(f\"   Schema: {TARGETSCHEMA}\")\n",
    "print(f\"   Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd841731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√µes auxiliares definidas!\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "def get_connection():\n",
    "    \"\"\"Conecta ao database de destino\"\"\"\n",
    "    try:\n",
    "        return psycopg2.connect(**DB_CONFIG)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao conectar: {e}\")\n",
    "        raise\n",
    "\n",
    "def clean_dataframe(df, table_name):\n",
    "    \"\"\"Limpa e prepara DataFrame para inser√ß√£o\"\"\"\n",
    "    logger.info(f\"üßπ Limpando dados para tabela: {table_name}\")\n",
    "    \n",
    "    # Remove aspas das colunas\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    \n",
    "    # Substitui NaN por None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    # Convers√µes espec√≠ficas por tabela\n",
    "    if table_name == 'clientes':\n",
    "        if 'data_nascimento' in df.columns:\n",
    "            df['data_nascimento'] = pd.to_datetime(df['data_nascimento'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'contas':\n",
    "        df = df.reset_index(drop=True)\n",
    "        if 'id_conta' in df.columns:\n",
    "            df['id_conta'] = np.arange(1, len(df) + 1, dtype=int)\n",
    "            logger.info(\"üî¢ Identificadores de contas normalizados com sequ√™ncia incremental (1..N).\")\n",
    "        if 'data_abertura' in df.columns:\n",
    "            df['data_abertura'] = pd.to_datetime(df['data_abertura'], errors='coerce')\n",
    "        if 'saldo' in df.columns:\n",
    "            df['saldo'] = pd.to_numeric(df['saldo'], errors='coerce').fillna(0)\n",
    "        if 'status' in df.columns:\n",
    "            df['status'] = df['status'].astype(str).str.strip().str.upper().str[:1]\n",
    "        \n",
    "    elif table_name == 'cartoes':\n",
    "        if 'numero_cartao' in df.columns:\n",
    "            df['numero_cartao'] = (\n",
    "                df['numero_cartao']\n",
    "                .astype(str)\n",
    "                .str.replace(r'\\D', '', regex=True)\n",
    "                .str.zfill(16)\n",
    "            )\n",
    "            duplicated_cards = df['numero_cartao'].duplicated(keep='first')\n",
    "            if duplicated_cards.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Cart√µes duplicados detectados em 'cartoes': {duplicated_cards.sum()} removidos.\"\n",
    "                )\n",
    "                df = df[~duplicated_cards].copy()\n",
    "        if 'id_cliente' in df.columns:\n",
    "            df['id_cliente'] = pd.to_numeric(df['id_cliente'], errors='coerce')\n",
    "            if df['id_cliente'].isna().any():\n",
    "                invalid_rows = df[df['id_cliente'].isna()]\n",
    "                logger.error(\n",
    "                    \"‚ùå Valores inv√°lidos para id_cliente em 'cartoes': \"\n",
    "                    + invalid_rows.to_json(orient='records', force_ascii=False)\n",
    "                )\n",
    "                raise ValueError(\"Valores inv√°lidos detectados na coluna id_cliente\")\n",
    "            df['id_cliente'] = df['id_cliente'].astype(int)\n",
    "        if 'data_emissao' in df.columns:\n",
    "            df['data_emissao'] = pd.to_datetime(df['data_emissao'], errors='coerce')\n",
    "        if 'limite_credito' in df.columns:\n",
    "            df['limite_credito'] = pd.to_numeric(df['limite_credito'], errors='coerce').fillna(0)\n",
    "        if 'status' in df.columns:\n",
    "            status_map = {\n",
    "                'ativo': 'A',\n",
    "                'bloqueado': 'B',\n",
    "                'cancelado': 'C',\n",
    "                'inativo': 'I',\n",
    "                'suspenso': 'S'\n",
    "            }\n",
    "            normalized_status = df['status'].astype(str).str.strip().str.lower()\n",
    "            df['status'] = normalized_status.map(status_map)\n",
    "            unmapped = df['status'].isna()\n",
    "            if unmapped.any():\n",
    "                logger.warning(\n",
    "                    \"‚ö†Ô∏è Valores de status n√£o mapeados em 'cartoes': \"\n",
    "                    + str(sorted(normalized_status[unmapped].unique()))\n",
    "                )\n",
    "                df.loc[unmapped, 'status'] = normalized_status[unmapped].str[:1].str.upper()\n",
    "        df = df.reset_index(drop=True)\n",
    "            \n",
    "    elif table_name == 'chaves_pix':\n",
    "        df = df.reset_index(drop=True)\n",
    "        if 'data_cadastro' in df.columns:\n",
    "            df['data_cadastro'] = pd.to_datetime(df['data_cadastro'], errors='coerce')\n",
    "        if 'id_cliente' in df.columns:\n",
    "            df['id_cliente'] = pd.to_numeric(df['id_cliente'], errors='coerce')\n",
    "        if 'id_conta' in df.columns:\n",
    "            df['id_conta'] = pd.to_numeric(df['id_conta'], errors='coerce')\n",
    "        if {'id_cliente', 'id_conta'}.issubset(df.columns):\n",
    "            numeric_invalid = df[['id_cliente', 'id_conta']].isna().any(axis=1)\n",
    "            if numeric_invalid.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Registros de chaves_pix com IDs inv√°lidos removidos: {numeric_invalid.sum()}\"\n",
    "                )\n",
    "                df = df[~numeric_invalid].copy()\n",
    "        if 'tipo_chave' in df.columns:\n",
    "            df['tipo_chave'] = df['tipo_chave'].astype(str).str.strip().str.lower()\n",
    "            valid_types = {'cpf', 'email', 'telefone', 'aleatoria'}\n",
    "            invalid_types = df[~df['tipo_chave'].isin(valid_types)]\n",
    "            if not invalid_types.empty:\n",
    "                logger.warning(\n",
    "                    \"‚ö†Ô∏è Tipos de chave n√£o suportados encontrados e removidos: \"\n",
    "                    + str(sorted(invalid_types['tipo_chave'].unique()))\n",
    "                )\n",
    "                df = df[df['tipo_chave'].isin(valid_types)].copy()\n",
    "        if 'valor_chave' in df.columns:\n",
    "            df['valor_chave'] = df['valor_chave'].astype(str).str.strip()\n",
    "            duplicated_keys = df['valor_chave'].duplicated(keep='first')\n",
    "            if duplicated_keys.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Chaves PIX duplicadas detectadas: {duplicated_keys.sum()} removidas.\"\n",
    "                )\n",
    "                df = df[~duplicated_keys].copy()\n",
    "        if 'status' in df.columns:\n",
    "            df['status'] = df['status'].astype(str).str.strip().str.upper().str[:1]\n",
    "            invalid_status = df['status'].isna() | ~df['status'].isin(['A', 'I'])\n",
    "            if invalid_status.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Status inv√°lidos em chaves_pix ajustados: {invalid_status.sum()}\"\n",
    "                )\n",
    "                df.loc[invalid_status, 'status'] = 'A'\n",
    "        # Remover coluna id_chave_pix se existir (√© SERIAL, gerado automaticamente)\n",
    "        if 'id_chave_pix' in df.columns:\n",
    "            df = df.drop(columns=['id_chave_pix'])\n",
    "        # Garantir consist√™ncia com contas j√° inseridas\n",
    "        try:\n",
    "            valid_accounts = get_existing_ids('contas', 'id_conta')\n",
    "            before = len(df)\n",
    "            df = df[df['id_conta'].isin(valid_accounts)].copy() if 'id_conta' in df.columns else df\n",
    "            removed = before - len(df)\n",
    "            if removed > 0:\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Chaves PIX com contas inexistentes removidas: {removed}\"\n",
    "                )\n",
    "        except Exception as lookup_error:\n",
    "            logger.error(f\"‚ùå Falha ao validar contas para chaves_pix: {lookup_error}\")\n",
    "            raise\n",
    "        df = df.reset_index(drop=True)\n",
    "            \n",
    "    elif table_name == 'transacoes':\n",
    "        df = df.reset_index(drop=True)\n",
    "        if 'id_transacao' in df.columns:\n",
    "            df['id_transacao'] = df['id_transacao'].astype(str).str.strip()\n",
    "            duplicated_ids = df['id_transacao'].duplicated(keep='first')\n",
    "            if duplicated_ids.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes duplicadas detectadas pelo id_transacao: {duplicated_ids.sum()} removidas.\"\n",
    "                )\n",
    "                df = df[~duplicated_ids].copy()\n",
    "        if 'id_conta' in df.columns:\n",
    "            df['id_conta'] = pd.to_numeric(df['id_conta'], errors='coerce')\n",
    "            invalid_accounts = df['id_conta'].isna()\n",
    "            if invalid_accounts.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes com id_conta inv√°lido removidas: {invalid_accounts.sum()}\"\n",
    "                )\n",
    "                df = df[~invalid_accounts].copy()\n",
    "            df['id_conta'] = df['id_conta'].astype(int)\n",
    "        if 'data_transacao' in df.columns:\n",
    "            df['data_transacao'] = pd.to_datetime(df['data_transacao'], errors='coerce')\n",
    "            invalid_dates = df['data_transacao'].isna()\n",
    "            if invalid_dates.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes com data_transacao inv√°lida removidas: {invalid_dates.sum()}\"\n",
    "                )\n",
    "                df = df[~invalid_dates].copy()\n",
    "        if 'valor' in df.columns:\n",
    "            df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "            invalid_values = df['valor'].isna()\n",
    "            if invalid_values.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes com valor inv√°lido removidas: {invalid_values.sum()}\"\n",
    "                )\n",
    "                df = df[~invalid_values].copy()\n",
    "        if 'tipo' in df.columns:\n",
    "            df['tipo'] = df['tipo'].astype(str).str.strip().str.upper().str[:1]\n",
    "            invalid_tipo = ~df['tipo'].isin(['C', 'D'])\n",
    "            if invalid_tipo.any():\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes com tipo inv√°lido ajustadas para 'D': {invalid_tipo.sum()}\"\n",
    "                )\n",
    "                df.loc[invalid_tipo, 'tipo'] = 'D'\n",
    "        if 'descricao' in df.columns:\n",
    "            df['descricao'] = df['descricao'].astype(str).str.strip()\n",
    "        # Validar refer√™ncias √† tabela de contas\n",
    "        try:\n",
    "            valid_accounts = get_existing_ids('contas', 'id_conta')\n",
    "            before = len(df)\n",
    "            df = df[df['id_conta'].isin(valid_accounts)].copy() if 'id_conta' in df.columns else df\n",
    "            removed = before - len(df)\n",
    "            if removed > 0:\n",
    "                logger.warning(\n",
    "                    f\"‚ö†Ô∏è Transa√ß√µes associadas a contas inexistentes removidas: {removed}\"\n",
    "                )\n",
    "        except Exception as lookup_error:\n",
    "            logger.error(f\"‚ùå Falha ao validar contas para transacoes: {lookup_error}\")\n",
    "            raise\n",
    "        df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_existing_ids(table_name, id_column):\n",
    "    \"\"\"Retorna um conjunto com os identificadores existentes em uma tabela.\"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\n",
    "            f'SELECT \"{id_column}\" FROM \"{TARGETSCHEMA}\".{table_name}'\n",
    "        )\n",
    "        return {row[0] for row in cursor.fetchall()}\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"Erro ao recuperar identificadores da tabela {table_name}.{id_column}: {e}\"\n",
    "        )\n",
    "        raise\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def insert_data_bulk(df, table_name, batch_size=1000):\n",
    "    \"\"\"Insere dados em lotes para melhor performance\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        logger.warning(f\"‚ö†Ô∏è DataFrame vazio recebido para {table_name}. Nenhum dado inserido.\")\n",
    "        return 0\n",
    "\n",
    "    conn = None\n",
    "    cursor = None\n",
    "\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Limpa tabela existente (se necess√°rio) com TRUNCATE para melhor performance\n",
    "        cursor.execute(f'TRUNCATE TABLE \"{TARGETSCHEMA}\".{table_name} RESTART IDENTITY CASCADE')\n",
    "        logger.info(f\"üóëÔ∏è Dados anteriores removidos de {table_name}\")\n",
    "\n",
    "        # Prepara dados para inser√ß√£o\n",
    "        columns = list(df.columns)\n",
    "        data_tuples = [tuple(x) for x in df.values]\n",
    "        values_template = '(' + ', '.join(['%s'] * len(columns)) + ')'\n",
    "        columns_str = ', '.join([f'\"{col}\"' for col in columns])\n",
    "\n",
    "        # Define cl√°usula ON CONFLICT espec√≠fica por tabela, quando aplic√°vel\n",
    "        conflict_clause = ''\n",
    "        if table_name == 'chaves_pix':\n",
    "            conflict_clause = ' ON CONFLICT (valor_chave) DO NOTHING'\n",
    "        elif table_name in ['agencias', 'clientes', 'contas', 'cartoes', 'transacoes']:\n",
    "            pk_column = {\n",
    "                'agencias': 'codigo_agencia',\n",
    "                'clientes': 'id_cliente', \n",
    "                'contas': 'id_conta',\n",
    "                'cartoes': 'numero_cartao',\n",
    "                'transacoes': 'id_transacao'\n",
    "            }[table_name]\n",
    "            conflict_clause = f' ON CONFLICT ({pk_column}) DO NOTHING'\n",
    "\n",
    "        insert_query = f'INSERT INTO \"{TARGETSCHEMA}\".{table_name} ({columns_str}) VALUES %s{conflict_clause}'\n",
    "\n",
    "        # Inser√ß√£o utilizando execute_values para melhor performance\n",
    "        execute_values(\n",
    "            cursor,\n",
    "            insert_query,\n",
    "            data_tuples,\n",
    "            template=values_template,\n",
    "            page_size=batch_size\n",
    "        )\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        # Verifica quantidade final\n",
    "        cursor.execute(f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".{table_name}')\n",
    "        final_count = cursor.fetchone()[0]\n",
    "\n",
    "        logger.info(f\"‚úÖ {table_name}: {final_count} registros inseridos com sucesso!\")\n",
    "        return final_count\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao inserir dados em {table_name}: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e19b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICANDO ESTRUTURA DAS TABELAS\n",
      "==================================================\n",
      "‚úÖ 6 tabelas encontradas no schema 'core_bank':\n",
      "\n",
      "üìã agencias (6 colunas):\n",
      "   ‚Ä¢ codigo_agencia: bigint (NOT NULL)\n",
      "   ‚Ä¢ nome: character varying (NOT NULL)\n",
      "   ‚Ä¢ endereco: text (NULL)\n",
      "   ‚Ä¢ cidade: character varying (NOT NULL)\n",
      "   ‚Ä¢ estado: character (NULL)\n",
      "   ‚Ä¢ telefone: character varying (NULL)\n",
      "‚úÖ 6 tabelas encontradas no schema 'core_bank':\n",
      "\n",
      "üìã agencias (6 colunas):\n",
      "   ‚Ä¢ codigo_agencia: bigint (NOT NULL)\n",
      "   ‚Ä¢ nome: character varying (NOT NULL)\n",
      "   ‚Ä¢ endereco: text (NULL)\n",
      "   ‚Ä¢ cidade: character varying (NOT NULL)\n",
      "   ‚Ä¢ estado: character (NULL)\n",
      "   ‚Ä¢ telefone: character varying (NULL)\n",
      "\n",
      "üìã cartoes (5 colunas):\n",
      "   ‚Ä¢ numero_cartao: character varying (NOT NULL)\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ data_emissao: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ limite_credito: numeric (NULL) [DEFAULT: 0]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã chaves_pix (7 colunas):\n",
      "   ‚Ä¢ id_chave_pix: integer (NOT NULL) [DEFAULT: nextval('core_bank.chaves_pix_id_chave_pix_seq'::regclass)]\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ tipo_chave: character varying (NOT NULL)\n",
      "   ‚Ä¢ valor_chave: character varying (NOT NULL)\n",
      "   ‚Ä¢ data_cadastro: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã cartoes (5 colunas):\n",
      "   ‚Ä¢ numero_cartao: character varying (NOT NULL)\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ data_emissao: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ limite_credito: numeric (NULL) [DEFAULT: 0]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã chaves_pix (7 colunas):\n",
      "   ‚Ä¢ id_chave_pix: integer (NOT NULL) [DEFAULT: nextval('core_bank.chaves_pix_id_chave_pix_seq'::regclass)]\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ tipo_chave: character varying (NOT NULL)\n",
      "   ‚Ä¢ valor_chave: character varying (NOT NULL)\n",
      "   ‚Ä¢ data_cadastro: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã clientes (7 colunas):\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ cpf: character varying (NOT NULL)\n",
      "   ‚Ä¢ nome: character varying (NOT NULL)\n",
      "   ‚Ä¢ data_nascimento: timestamp without time zone (NULL)\n",
      "   ‚Ä¢ genero: character (NULL)\n",
      "   ‚Ä¢ email: character varying (NULL)\n",
      "   ‚Ä¢ telefone: character varying (NULL)\n",
      "\n",
      "üìã clientes (7 colunas):\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ cpf: character varying (NOT NULL)\n",
      "   ‚Ä¢ nome: character varying (NOT NULL)\n",
      "   ‚Ä¢ data_nascimento: timestamp without time zone (NULL)\n",
      "   ‚Ä¢ genero: character (NULL)\n",
      "   ‚Ä¢ email: character varying (NULL)\n",
      "   ‚Ä¢ telefone: character varying (NULL)\n",
      "\n",
      "üìã contas (6 colunas):\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ codigo_agencia: bigint (NOT NULL)\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ saldo: numeric (NULL) [DEFAULT: 0]\n",
      "   ‚Ä¢ data_abertura: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã transacoes (6 colunas):\n",
      "   ‚Ä¢ id_transacao: character varying (NOT NULL)\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ data_transacao: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ valor: numeric (NOT NULL)\n",
      "   ‚Ä¢ tipo: character (NOT NULL)\n",
      "   ‚Ä¢ descricao: text (NULL)\n",
      "\n",
      "üìã contas (6 colunas):\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ codigo_agencia: bigint (NOT NULL)\n",
      "   ‚Ä¢ id_cliente: bigint (NOT NULL)\n",
      "   ‚Ä¢ saldo: numeric (NULL) [DEFAULT: 0]\n",
      "   ‚Ä¢ data_abertura: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ status: character (NULL) [DEFAULT: 'A'::bpchar]\n",
      "\n",
      "üìã transacoes (6 colunas):\n",
      "   ‚Ä¢ id_transacao: character varying (NOT NULL)\n",
      "   ‚Ä¢ id_conta: bigint (NOT NULL)\n",
      "   ‚Ä¢ data_transacao: timestamp without time zone (NULL) [DEFAULT: CURRENT_TIMESTAMP]\n",
      "   ‚Ä¢ valor: numeric (NOT NULL)\n",
      "   ‚Ä¢ tipo: character (NOT NULL)\n",
      "   ‚Ä¢ descricao: text (NULL)\n"
     ]
    }
   ],
   "source": [
    "# Verifica√ß√£o das tabelas antes da inser√ß√£o\n",
    "def verify_table_structure():\n",
    "    \"\"\"Verifica se as tabelas existem e mostra sua estrutura\"\"\"\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(\"üîç VERIFICANDO ESTRUTURA DAS TABELAS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Lista tabelas no schema\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = %s \n",
    "            ORDER BY table_name\n",
    "        \"\"\", (TARGETSCHEMA,))\n",
    "        \n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        if not tables:\n",
    "            print(f\"‚ùå Nenhuma tabela encontrada no schema '{TARGETSCHEMA}'\")\n",
    "            print(\"Execute primeiro o notebook 01_setup_database_and_tables.ipynb\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úÖ {len(tables)} tabelas encontradas no schema '{TARGETSCHEMA}':\")\n",
    "        \n",
    "        for (table_name,) in tables:\n",
    "            # Mostra colunas da tabela\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT column_name, data_type, is_nullable, column_default\n",
    "                FROM information_schema.columns \n",
    "                WHERE table_schema = %s AND table_name = %s\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\", (TARGETSCHEMA, table_name))\n",
    "            \n",
    "            columns = cursor.fetchall()\n",
    "            print(f\"\\nüìã {table_name} ({len(columns)} colunas):\")\n",
    "            \n",
    "            for col_name, data_type, nullable, default in columns:\n",
    "                nullable_str = \"NULL\" if nullable == \"YES\" else \"NOT NULL\"\n",
    "                default_str = f\" [DEFAULT: {default}]\" if default else \"\"\n",
    "                print(f\"   ‚Ä¢ {col_name}: {data_type} ({nullable_str}){default_str}\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao verificar estrutura: {e}\")\n",
    "        return False\n",
    "\n",
    "# Executar verifica√ß√£o\n",
    "if not verify_table_structure():\n",
    "    raise Exception(\"Estrutura das tabelas n√£o est√° correta. Execute primeiro o notebook 01.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80de0d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ VERIFICANDO ARQUIVOS CSV\n",
      "========================================\n",
      "‚úÖ agencias.csv (12,689 bytes)\n",
      "‚úÖ clientes.csv (89,568 bytes)\n",
      "‚úÖ contas.csv (51,114 bytes)\n",
      "‚úÖ cartoes.csv (85,252 bytes)\n",
      "‚úÖ chaves_pix.csv (57,286 bytes)\n",
      "‚úÖ transacoes.csv (1,627,385 bytes)\n",
      "\n",
      "‚úÖ Todos os 6 arquivos CSV encontrados!\n"
     ]
    }
   ],
   "source": [
    "# Verifica√ß√£o dos arquivos CSV\n",
    "def verify_csv_files():\n",
    "    \"\"\"Verifica se todos os arquivos CSV necess√°rios existem\"\"\"\n",
    "    print(\"\\nüìÇ VERIFICANDO ARQUIVOS CSV\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    required_files = [\n",
    "        'agencias.csv',\n",
    "        'clientes.csv', \n",
    "        'contas.csv',\n",
    "        'cartoes.csv',\n",
    "        'chaves_pix.csv',\n",
    "        'transacoes.csv'\n",
    "    ]\n",
    "    \n",
    "    missing_files = []\n",
    "    existing_files = []\n",
    "    \n",
    "    for csv_file in required_files:\n",
    "        file_path = os.path.join(DATA_PATH, csv_file)\n",
    "        if os.path.exists(file_path):\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            existing_files.append((csv_file, file_size))\n",
    "            print(f\"‚úÖ {csv_file} ({file_size:,} bytes)\")\n",
    "        else:\n",
    "            missing_files.append(csv_file)\n",
    "            print(f\"‚ùå {csv_file} - ARQUIVO N√ÉO ENCONTRADO\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\n‚ö†Ô∏è {len(missing_files)} arquivo(s) faltando:\")\n",
    "        for file in missing_files:\n",
    "            print(f\"   ‚Ä¢ {file}\")\n",
    "        print(f\"\\nVerifique o caminho: {os.path.abspath(DATA_PATH)}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n‚úÖ Todos os {len(existing_files)} arquivos CSV encontrados!\")\n",
    "    return True\n",
    "\n",
    "# Verificar arquivos CSV\n",
    "if not verify_csv_files():\n",
    "    raise Exception(\"Arquivos CSV n√£o encontrados. Verifique o caminho dos dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe7a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:16,418 - INFO - üè¢ Processando AG√äNCIAS...\n",
      "2025-09-25 07:00:16,436 - INFO - üßπ Limpando dados para tabela: agencias\n",
      "2025-09-25 07:00:16,436 - INFO - üßπ Limpando dados para tabela: agencias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ag√™ncias carregadas: 167 registros\n",
      "üìã Colunas: ['codigo_agencia', 'nome', 'endereco', 'cidade', 'estado', 'telefone']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "   codigo_agencia          nome               endereco    cidade estado  \\\n",
      "0            7210  Ag√™ncia 7210      Alameda Sousa, 43  Teixeira     AM   \n",
      "1            9674  Ag√™ncia 9674  Col√¥nia de Rocha, 719    Macedo     ES   \n",
      "2            3137  Ag√™ncia 3137          Ch√°cara Cunha     Sales     PA   \n",
      "\n",
      "              telefone  \n",
      "0         84 6528-1685  \n",
      "1  +55 (031) 5423 5733  \n",
      "2     +55 84 2141 8880  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:18,245 - INFO - üóëÔ∏è Dados anteriores removidos de agencias\n",
      "2025-09-25 07:00:18,964 - INFO - ‚úÖ agencias: 166 registros inseridos com sucesso!\n",
      "2025-09-25 07:00:18,964 - INFO - ‚úÖ agencias: 166 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ AG√äNCIAS: 166 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert AGENCIAS\n",
    "logger.info(\"üè¢ Processando AG√äNCIAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_agencias = pd.read_csv(f\"{DATA_PATH}agencias.csv\")\n",
    "    df_agencias = clean_dataframe(df_agencias, 'agencias')\n",
    "    \n",
    "    print(f\"üìä Ag√™ncias carregadas: {len(df_agencias):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_agencias.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_agencias.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_agencias = insert_data_bulk(df_agencias, 'agencias')\n",
    "    print(f\"\\n‚úÖ AG√äNCIAS: {count_agencias:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar ag√™ncias: {e}\")\n",
    "    count_agencias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496d8f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:18,973 - INFO - üë• Processando CLIENTES...\n",
      "2025-09-25 07:00:18,982 - INFO - üßπ Limpando dados para tabela: clientes\n",
      "2025-09-25 07:00:18,982 - INFO - üßπ Limpando dados para tabela: clientes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Clientes carregados: 1,000 registros\n",
      "üìã Colunas: ['id_cliente', 'cpf', 'nome', 'data_nascimento', 'genero', 'email', 'telefone']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "   id_cliente             cpf                 nome data_nascimento genero  \\\n",
      "0           1  941.730.258-23  Jo√£o Vitor da Rocha      1992-05-19      M   \n",
      "1           2  718.342.596-73    Dr. Oliver Garcia      1966-12-02      M   \n",
      "2           3  745.629.183-73          Paulo Cunha      1998-04-17      M   \n",
      "\n",
      "                   email          telefone  \n",
      "0   joao.rocha@email.com  +55 81 3253 6729  \n",
      "1   dr..garcia@email.com     0800 017 5186  \n",
      "2  paulo.cunha@email.com   (081) 0017 0127  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:20,477 - INFO - üóëÔ∏è Dados anteriores removidos de clientes\n",
      "2025-09-25 07:00:21,642 - INFO - ‚úÖ clientes: 1000 registros inseridos com sucesso!\n",
      "2025-09-25 07:00:21,642 - INFO - ‚úÖ clientes: 1000 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ CLIENTES: 1,000 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert CLIENTES\n",
    "logger.info(\"üë• Processando CLIENTES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_clientes = pd.read_csv(f\"{DATA_PATH}clientes.csv\")\n",
    "    df_clientes = clean_dataframe(df_clientes, 'clientes')\n",
    "    \n",
    "    print(f\"üìä Clientes carregados: {len(df_clientes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_clientes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_clientes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_clientes = insert_data_bulk(df_clientes, 'clientes')\n",
    "    print(f\"\\n‚úÖ CLIENTES: {count_clientes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar clientes: {e}\")\n",
    "    count_clientes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a6be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:21,651 - INFO - üè¶ Processando CONTAS...\n",
      "2025-09-25 07:00:21,657 - INFO - üßπ Limpando dados para tabela: contas\n",
      "2025-09-25 07:00:21,657 - INFO - üßπ Limpando dados para tabela: contas\n",
      "2025-09-25 07:00:21,659 - INFO - üî¢ Identificadores de contas normalizados com sequ√™ncia incremental (1..N).\n",
      "2025-09-25 07:00:21,659 - INFO - üî¢ Identificadores de contas normalizados com sequ√™ncia incremental (1..N).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Contas carregadas: 1,258 registros\n",
      "üìã Colunas: ['id_conta', 'codigo_agencia', 'id_cliente', 'saldo', 'data_abertura', 'status']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "   id_conta  codigo_agencia  id_cliente     saldo data_abertura status\n",
      "0         1            4593           1  22844.46    2024-09-11      A\n",
      "1         2            5430           1  28978.37    2025-04-28      A\n",
      "2         3            6840           2  39177.64    2023-02-13      A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:38,400 - INFO - üóëÔ∏è Dados anteriores removidos de contas\n",
      "2025-09-25 07:00:40,214 - INFO - ‚úÖ contas: 1258 registros inseridos com sucesso!\n",
      "2025-09-25 07:00:40,214 - INFO - ‚úÖ contas: 1258 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ CONTAS: 1,258 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert CONTAS\n",
    "logger.info(\"üè¶ Processando CONTAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_contas = pd.read_csv(f\"{DATA_PATH}contas.csv\")\n",
    "    df_contas = clean_dataframe(df_contas, 'contas')\n",
    "    \n",
    "    print(f\"üìä Contas carregadas: {len(df_contas):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_contas.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_contas.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_contas = insert_data_bulk(df_contas, 'contas')\n",
    "    print(f\"\\n‚úÖ CONTAS: {count_contas:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar contas: {e}\")\n",
    "    count_contas = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eacc4b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:40,224 - INFO - üí≥ Processando CART√ïES...\n",
      "2025-09-25 07:00:40,232 - INFO - üßπ Limpando dados para tabela: cartoes\n",
      "2025-09-25 07:00:40,232 - INFO - üßπ Limpando dados para tabela: cartoes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Cart√µes carregados: 1,425 registros\n",
      "üìã Colunas: ['numero_cartao', 'id_cliente', 'data_emissao', 'limite_credito', 'status']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "      numero_cartao  id_cliente data_emissao  limite_credito status\n",
      "0  0000000000000001          92   2024-02-10        13690.37      C\n",
      "1  0000000000000002          92   2023-07-22         7597.15      B\n",
      "2  0000000000000003         850   2021-10-09        14792.67      C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:41,740 - INFO - üóëÔ∏è Dados anteriores removidos de cartoes\n",
      "2025-09-25 07:00:42,875 - INFO - ‚úÖ cartoes: 1425 registros inseridos com sucesso!\n",
      "2025-09-25 07:00:42,875 - INFO - ‚úÖ cartoes: 1425 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ CART√ïES: 1,425 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert CARTOES\n",
    "logger.info(\"üí≥ Processando CART√ïES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_cartoes = pd.read_csv(f\"{DATA_PATH}cartoes.csv\")\n",
    "    df_cartoes = clean_dataframe(df_cartoes, 'cartoes')\n",
    "    \n",
    "    print(f\"üìä Cart√µes carregados: {len(df_cartoes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_cartoes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_cartoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_cartoes = insert_data_bulk(df_cartoes, 'cartoes')\n",
    "    print(f\"\\n‚úÖ CART√ïES: {count_cartoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar cart√µes: {e}\")\n",
    "    count_cartoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfac733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:00:42,886 - INFO - üîë Processando CHAVES PIX...\n",
      "2025-09-25 07:00:42,893 - INFO - üßπ Limpando dados para tabela: chaves_pix\n",
      "2025-09-25 07:00:42,893 - INFO - üßπ Limpando dados para tabela: chaves_pix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Chaves PIX carregadas: 898 registros\n",
      "üìã Colunas: ['id_cliente', 'id_conta', 'tipo_chave', 'valor_chave', 'data_cadastro', 'status']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "   id_cliente  id_conta tipo_chave                           valor_chave  \\\n",
      "0         885      1115        cpf                        895.376.421-19   \n",
      "1         424       535      email               da-cruzluan@example.net   \n",
      "2          59        76  aleatoria  10fa62fc-a9b2-4838-adac-4484f2d058ca   \n",
      "\n",
      "  data_cadastro status  \n",
      "0    2023-12-02      A  \n",
      "1    2024-09-10      A  \n",
      "2    2023-12-25      I  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:01:01,761 - INFO - üóëÔ∏è Dados anteriores removidos de chaves_pix\n",
      "2025-09-25 07:01:02,829 - INFO - ‚úÖ chaves_pix: 898 registros inseridos com sucesso!\n",
      "2025-09-25 07:01:02,829 - INFO - ‚úÖ chaves_pix: 898 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ CHAVES PIX: 898 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert CHAVES PIX\n",
    "logger.info(\"üîë Processando CHAVES PIX...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_chaves_pix = pd.read_csv(f\"{DATA_PATH}chaves_pix.csv\")\n",
    "    df_chaves_pix = clean_dataframe(df_chaves_pix, 'chaves_pix')\n",
    "    \n",
    "    print(f\"üìä Chaves PIX carregadas: {len(df_chaves_pix):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_chaves_pix.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_chaves_pix.head(3))\n",
    "    \n",
    "    # Verificar se a coluna id_chave_pix existe e remover (√© SERIAL)\n",
    "    if 'id_chave_pix' in df_chaves_pix.columns:\n",
    "        print(\"‚ÑπÔ∏è  Removendo coluna id_chave_pix (gerada automaticamente)\")\n",
    "        df_chaves_pix = df_chaves_pix.drop(columns=['id_chave_pix'])\n",
    "        print(f\"üìã Colunas ap√≥s limpeza: {list(df_chaves_pix.columns)}\")\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_chaves_pix = insert_data_bulk(df_chaves_pix, 'chaves_pix')\n",
    "    print(f\"\\n‚úÖ CHAVES PIX: {count_chaves_pix:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar chaves PIX: {e}\")\n",
    "    count_chaves_pix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9554ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:01:02,839 - INFO - üí∏ Processando TRANSA√á√ïES...\n",
      "2025-09-25 07:01:02,873 - INFO - üßπ Limpando dados para tabela: transacoes\n",
      "2025-09-25 07:01:02,873 - INFO - üßπ Limpando dados para tabela: transacoes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Transa√ß√µes carregadas: 14,941 registros\n",
      "üìã Colunas: ['id_transacao', 'id_conta', 'data_transacao', 'valor', 'tipo', 'descricao']\n",
      "\n",
      "üìù Amostra dos dados:\n",
      "                 id_transacao  id_conta      data_transacao     valor tipo  \\\n",
      "0  01050145240015669831979203       865 2024-01-01 05:45:00  65434.03    C   \n",
      "1  01120148241104867493468074       274 2024-01-01 12:48:11  63778.18    C   \n",
      "2  01000154240222183622592252       162 2024-01-01 00:54:02  80253.20    D   \n",
      "\n",
      "                                    descricao  \n",
      "0  Transa√ß√£o C - Conta 79138-9 - Ag√™ncia 6651  \n",
      "1  Transa√ß√£o C - Conta 64394-7 - Ag√™ncia 6840  \n",
      "2  Transa√ß√£o D - Conta 95226-3 - Ag√™ncia 8122  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:01:05,857 - INFO - üóëÔ∏è Dados anteriores removidos de transacoes\n",
      "2025-09-25 07:01:10,079 - INFO - ‚úÖ transacoes: 14941 registros inseridos com sucesso!\n",
      "2025-09-25 07:01:10,079 - INFO - ‚úÖ transacoes: 14941 registros inseridos com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ TRANSA√á√ïES: 14,941 registros inseridos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert TRANSACOES\n",
    "logger.info(\"üí∏ Processando TRANSA√á√ïES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_transacoes = pd.read_csv(f\"{DATA_PATH}transacoes.csv\")\n",
    "    df_transacoes = clean_dataframe(df_transacoes, 'transacoes')\n",
    "    \n",
    "    print(f\"üìä Transa√ß√µes carregadas: {len(df_transacoes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_transacoes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_transacoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_transacoes = insert_data_bulk(df_transacoes, 'transacoes')\n",
    "    print(f\"\\n‚úÖ TRANSA√á√ïES: {count_transacoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar transa√ß√µes: {e}\")\n",
    "    count_transacoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ea0c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VALIDA√á√ÉO DE INTEGRIDADE DOS DADOS\n",
      "============================================================\n",
      "üìä Total de ag√™ncias: 166\n",
      "üìä Total de clientes: 1000\n",
      "üìä Total de ag√™ncias: 166\n",
      "üìä Total de clientes: 1000\n",
      "üìä Total de contas: 1258\n",
      "üìä Total de cart√µes: 1425\n",
      "üìä Total de contas: 1258\n",
      "üìä Total de cart√µes: 1425\n",
      "üìä Total de chaves PIX: 898\n",
      "üìä Total de transa√ß√µes: 14941\n",
      "üìä Total de chaves PIX: 898\n",
      "üìä Total de transa√ß√µes: 14941\n",
      "üìä Contas com saldo > 0: 1258\n",
      "üìä Clientes √∫nicos: 1000\n",
      "üìä Contas com saldo > 0: 1258\n",
      "üìä Clientes √∫nicos: 1000\n",
      "üìä Soma total dos saldos: 32209163.07\n",
      "üìä Per√≠odo das transa√ß√µes: [Timestamp('2024-01-01 00:25:42'), Timestamp('2024-05-15 23:48:43')]\n",
      "\n",
      "üîó VERIFICA√á√ïES DE INTEGRIDADE REFERENCIAL\n",
      "--------------------------------------------------\n",
      "üìä Soma total dos saldos: 32209163.07\n",
      "üìä Per√≠odo das transa√ß√µes: [Timestamp('2024-01-01 00:25:42'), Timestamp('2024-05-15 23:48:43')]\n",
      "\n",
      "üîó VERIFICA√á√ïES DE INTEGRIDADE REFERENCIAL\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 07:01:34,392 - ERROR - Erro ao conectar: connection to server at \"pgdtgov5wm5wmynq.postgres.database.azure.com\" (135.119.41.214), port 5432 failed: Connection timed out (0x0000274C/10060)\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "2025-09-25 07:01:34,393 - ERROR - ‚ùå Erro na valida√ß√£o: connection to server at \"pgdtgov5wm5wmynq.postgres.database.azure.com\" (135.119.41.214), port 5432 failed: Connection timed out (0x0000274C/10060)\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "2025-09-25 07:01:34,393 - ERROR - ‚ùå Erro na valida√ß√£o: connection to server at \"pgdtgov5wm5wmynq.postgres.database.azure.com\" (135.119.41.214), port 5432 failed: Connection timed out (0x0000274C/10060)\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Validation and Verification\n",
    "def validate_data_integrity():\n",
    "    \"\"\"Valida a integridade dos dados inseridos\"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        \n",
    "        print(\"üîç VALIDA√á√ÉO DE INTEGRIDADE DOS DADOS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Valida√ß√µes b√°sicas\n",
    "        validations = {\n",
    "            \"Total de ag√™ncias\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".agencias',\n",
    "            \"Total de clientes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Total de contas\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"Total de cart√µes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes',\n",
    "            \"Total de chaves PIX\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".chaves_pix',\n",
    "            \"Total de transa√ß√µes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes',\n",
    "            \"Contas com saldo > 0\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas WHERE saldo > 0',\n",
    "            \"Clientes √∫nicos\": f'SELECT COUNT(DISTINCT id_cliente) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Soma total dos saldos\": f'SELECT SUM(saldo) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"Per√≠odo das transa√ß√µes\": f'SELECT MIN(data_transacao), MAX(data_transacao) FROM \"{TARGETSCHEMA}\".transacoes'\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for description, query in validations.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                result = df_result.iloc[0, 0] if len(df_result.columns) == 1 else df_result.iloc[0].tolist()\n",
    "                results[description] = result\n",
    "                print(f\"üìä {description}: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {description}: Erro - {e}\")\n",
    "                results[description] = \"ERRO\"\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        # Verifica√ß√µes de integridade referencial\n",
    "        print(f\"\\nüîó VERIFICA√á√ïES DE INTEGRIDADE REFERENCIAL\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        conn = get_connection()\n",
    "        \n",
    "        integrity_checks = {\n",
    "            \"Contas √≥rf√£s (sem cliente)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"Contas √≥rf√£s (sem ag√™ncia)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".agencias a ON c.codigo_agencia = a.codigo_agencia \n",
    "                WHERE a.codigo_agencia IS NULL\n",
    "            ''',\n",
    "            \"Cart√µes √≥rf√£os\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"Transa√ß√µes √≥rf√£s\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes t \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".contas c ON t.id_conta = c.id_conta \n",
    "                WHERE c.id_conta IS NULL\n",
    "            '''\n",
    "        }\n",
    "        \n",
    "        for description, query in integrity_checks.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                orphans = df_result.iloc[0, 0]\n",
    "                status = \"‚úÖ OK\" if orphans == 0 else f\"‚ö†Ô∏è {orphans} registros √≥rf√£os\"\n",
    "                print(f\"{description}: {status}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{description}: ‚ùå Erro - {e}\")\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro na valida√ß√£o: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "validation_results = validate_data_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d7f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä RELAT√ìRIO FINAL - INSER√á√ÉO DE DADOS PRINCIPAIS\n",
      "================================================================================\n",
      "üóìÔ∏è Data/Hora: 25/09/2025 07:01:34\n",
      "üéØ Database: mkl_bank\n",
      "üè∑Ô∏è Schema: core_bank\n",
      "\n",
      "üìà RESUMO DAS INSER√á√ïES:\n",
      "----------------------------------------\n",
      "‚úÖ Ag√™ncias.................        166 registros\n",
      "‚úÖ Clientes.................      1,000 registros\n",
      "‚úÖ Contas...................      1,258 registros\n",
      "‚úÖ Cart√µes..................      1,425 registros\n",
      "‚úÖ Chaves PIX...............        898 registros\n",
      "‚úÖ Transa√ß√µes...............     14,941 registros\n",
      "----------------------------------------\n",
      "üéØ TOTAL DE REGISTROS..........     19,688\n",
      "\n",
      "üöÄ STATUS: ‚úÖ SUCESSO\n",
      "\n",
      "üìã PR√ìXIMOS PASSOS:\n",
      "1. ‚úÖ Dados principais inseridos com sucesso\n",
      "2. üîÑ Execute o notebook: 03_insert_movement_data.ipynb\n",
      "3. üìä Verifique os dados de movimenta√ß√µes\n",
      "4. üèóÔ∏è Inicie a arquitetura medalh√£o (Bronze/Silver/Gold)\n"
     ]
    }
   ],
   "source": [
    "# Summary Report\n",
    "def generate_summary_report():\n",
    "    \"\"\"Gera relat√≥rio resumo da inser√ß√£o\"\"\"\n",
    "    \n",
    "    # Contadores das inser√ß√µes\n",
    "    insertion_counts = {\n",
    "        'Ag√™ncias': count_agencias if 'count_agencias' in globals() else 0,\n",
    "        'Clientes': count_clientes if 'count_clientes' in globals() else 0,\n",
    "        'Contas': count_contas if 'count_contas' in globals() else 0,\n",
    "        'Cart√µes': count_cartoes if 'count_cartoes' in globals() else 0,\n",
    "        'Chaves PIX': count_chaves_pix if 'count_chaves_pix' in globals() else 0,\n",
    "        'Transa√ß√µes': count_transacoes if 'count_transacoes' in globals() else 0\n",
    "    }\n",
    "    \n",
    "    total_records = sum(insertion_counts.values())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä RELAT√ìRIO FINAL - INSER√á√ÉO DE DADOS PRINCIPAIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"üóìÔ∏è Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "    print(f\"üéØ Database: {TARGET_DB}\")\n",
    "    print(f\"üè∑Ô∏è Schema: {TARGETSCHEMA}\")\n",
    "    \n",
    "    print(f\"\\nüìà RESUMO DAS INSER√á√ïES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for table_name, count in insertion_counts.items():\n",
    "        status = \"‚úÖ\" if count > 0 else \"‚ùå\"\n",
    "        print(f\"{status} {table_name:.<25} {count:>10,} registros\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"üéØ TOTAL DE REGISTROS.......... {total_records:>10,}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ STATUS: {'‚úÖ SUCESSO' if total_records > 0 else '‚ùå FALHA'}\")\n",
    "    \n",
    "    if total_records > 0:\n",
    "        print(f\"\\nüìã PR√ìXIMOS PASSOS:\")\n",
    "        print(\"1. ‚úÖ Dados principais inseridos com sucesso\")\n",
    "        print(\"2. üîÑ Execute o notebook: 03_insert_movement_data.ipynb\")\n",
    "        print(\"3. üìä Verifique os dados de movimenta√ß√µes\")\n",
    "        print(\"4. üèóÔ∏è Inicie a arquitetura medalh√£o (Bronze/Silver/Gold)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è A√á√ïES NECESS√ÅRIAS:\")\n",
    "        print(\"1. Verifique as configura√ß√µes de conex√£o\")\n",
    "        print(\"2. Confirme se os arquivos CSV existem\")\n",
    "        print(\"3. Verifique os logs de erro acima\")\n",
    "    \n",
    "    return {\n",
    "        'total_records': total_records,\n",
    "        'insertion_counts': insertion_counts,\n",
    "        'timestamp': datetime.now()\n",
    "    }\n",
    "\n",
    "# Gerar relat√≥rio\n",
    "final_report = generate_summary_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091742cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
      "üîß CORRE√á√ïES APLICADAS NO NOTEBOOK 02\n",
      "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
      "\n",
      "‚úÖ PROBLEMAS CORRIGIDOS:\n",
      "1. üîÑ Database Configuration:\n",
      "   ‚Ä¢ Alterado de 'fsi_db' para 'mkl_bank' (alinhado com notebook 01)\n",
      "   ‚Ä¢ Port convertido para int()\n",
      "   ‚Ä¢ Adicionado sslmode e connect_timeout\n",
      "\n",
      "2. üè∑Ô∏è Schema Configuration:\n",
      "   ‚Ä¢ Alterado de 'public' para 'core_bank'\n",
      "   ‚Ä¢ TARGETSCHEMA atualizado corretamente\n",
      "\n",
      "3. üìù Fun√ß√£o clean_dataframe:\n",
      "   ‚Ä¢ Adicionado tratamento para 'data_cadastro' em chaves_pix\n",
      "   ‚Ä¢ Remo√ß√£o autom√°tica da coluna 'id_chave_pix' (SERIAL)\n",
      "\n",
      "4. üìä Fun√ß√£o insert_data_bulk:\n",
      "   ‚Ä¢ Alterado DELETE para TRUNCATE (melhor performance)\n",
      "   ‚Ä¢ Adicionado ON CONFLICT para evitar erros de chave duplicada\n",
      "   ‚Ä¢ Tratamento espec√≠fico para SERIAL na tabela chaves_pix\n",
      "\n",
      "5. ‚úîÔ∏è Verifica√ß√µes adicionais:\n",
      "   ‚Ä¢ Verifica√ß√£o da estrutura das tabelas antes da inser√ß√£o\n",
      "   ‚Ä¢ Verifica√ß√£o da exist√™ncia dos arquivos CSV\n",
      "   ‚Ä¢ Valida√ß√£o de integridade referencial aprimorada\n",
      "\n",
      "6. üõ°Ô∏è Tratamento de erros:\n",
      "   ‚Ä¢ ON CONFLICT DO NOTHING para evitar falhas\n",
      "   ‚Ä¢ Valida√ß√£o de pr√©-requisitos\n",
      "   ‚Ä¢ Logs mais detalhados\n",
      "\n",
      "‚úÖ NOTEBOOK 02 TOTALMENTE CORRIGIDO E ALINHADO COM NOTEBOOK 01!\n",
      "üöÄ Pronto para executar as inser√ß√µes no database 'mkl_bank' schema 'core_bank'\n"
     ]
    }
   ],
   "source": [
    "# üéâ RESUMO DAS CORRE√á√ïES APLICADAS\n",
    "print(\"\\n\" + \"üîß\" * 60)\n",
    "print(\"üîß CORRE√á√ïES APLICADAS NO NOTEBOOK 02\")  \n",
    "print(\"üîß\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ PROBLEMAS CORRIGIDOS:\")\n",
    "print(\"1. üîÑ Database Configuration:\")\n",
    "print(\"   ‚Ä¢ Alterado de 'fsi_db' para 'mkl_bank' (alinhado com notebook 01)\")\n",
    "print(\"   ‚Ä¢ Port convertido para int()\")\n",
    "print(\"   ‚Ä¢ Adicionado sslmode e connect_timeout\")\n",
    "\n",
    "print(\"\\n2. üè∑Ô∏è Schema Configuration:\")\n",
    "print(\"   ‚Ä¢ Alterado de 'public' para 'core_bank'\")\n",
    "print(\"   ‚Ä¢ TARGETSCHEMA atualizado corretamente\")\n",
    "\n",
    "print(\"\\n3. üìù Fun√ß√£o clean_dataframe:\")\n",
    "print(\"   ‚Ä¢ Adicionado tratamento para 'data_cadastro' em chaves_pix\")\n",
    "print(\"   ‚Ä¢ Remo√ß√£o autom√°tica da coluna 'id_chave_pix' (SERIAL)\")\n",
    "\n",
    "print(\"\\n4. üìä Fun√ß√£o insert_data_bulk:\")\n",
    "print(\"   ‚Ä¢ Alterado DELETE para TRUNCATE (melhor performance)\")\n",
    "print(\"   ‚Ä¢ Adicionado ON CONFLICT para evitar erros de chave duplicada\")\n",
    "print(\"   ‚Ä¢ Tratamento espec√≠fico para SERIAL na tabela chaves_pix\")\n",
    "\n",
    "print(\"\\n5. ‚úîÔ∏è Verifica√ß√µes adicionais:\")\n",
    "print(\"   ‚Ä¢ Verifica√ß√£o da estrutura das tabelas antes da inser√ß√£o\")\n",
    "print(\"   ‚Ä¢ Verifica√ß√£o da exist√™ncia dos arquivos CSV\")\n",
    "print(\"   ‚Ä¢ Valida√ß√£o de integridade referencial aprimorada\")\n",
    "\n",
    "print(\"\\n6. üõ°Ô∏è Tratamento de erros:\")\n",
    "print(\"   ‚Ä¢ ON CONFLICT DO NOTHING para evitar falhas\")\n",
    "print(\"   ‚Ä¢ Valida√ß√£o de pr√©-requisitos\")\n",
    "print(\"   ‚Ä¢ Logs mais detalhados\")\n",
    "\n",
    "print(f\"\\n‚úÖ NOTEBOOK 02 TOTALMENTE CORRIGIDO E ALINHADO COM NOTEBOOK 01!\")\n",
    "print(f\"üöÄ Pronto para executar as inser√ß√µes no database '{TARGET_DB}' schema '{TARGETSCHEMA}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7374269",
   "metadata": {},
   "source": [
    "## ‚úÖ Inser√ß√£o de Dados Principais Conclu√≠da!\n",
    "\n",
    "### üìä Resultados Alcan√ßados:\n",
    "- **Ag√™ncias, Clientes, Contas, Cart√µes, Chaves PIX e Transa√ß√µes** inseridos\n",
    "- **Valida√ß√£o de integridade** executada com sucesso\n",
    "- **Verifica√ß√£o de relacionamentos** confirmada\n",
    "- **Sistema preparado** para receber dados de movimenta√ß√µes\n",
    "\n",
    "### üîó Integridade Referencial:\n",
    "- Todas as Foreign Keys validadas\n",
    "- Relacionamentos entre tabelas verificados\n",
    "- Sem registros √≥rf√£os detectados\n",
    "\n",
    "### üöÄ Pr√≥ximo Passo:\n",
    "Execute o notebook **`03_insert_movement_data.ipynb`** para inserir os dados de movimenta√ß√µes (boletos, PIX, transfer√™ncias, etc.)\n",
    "\n",
    "### üìà Performance:\n",
    "- Inser√ß√£o realizada em lotes para otimiza√ß√£o\n",
    "- Indexa√ß√£o autom√°tica atrav√©s das Primary Keys\n",
    "- Constraints aplicadas corretamente\n",
    "\n",
    "**üéâ Sistema core do MKL Bank pronto para opera√ß√£o!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-governance-with-purview-fabric-and-databricks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
