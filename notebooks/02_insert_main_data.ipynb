{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b16a13",
   "metadata": {},
   "source": [
    "# Inser√ß√£o de Dados Principais - MKL Bank\n",
    "\n",
    "Este notebook insere os dados principais do sistema banc√°rio: ag√™ncias, clientes, contas, cart√µes, chaves PIX e transa√ß√µes.\n",
    "\n",
    "## Objetivo\n",
    "- Carregar e inserir dados das tabelas principais\n",
    "- Validar integridade referencial\n",
    "- Verificar inser√ß√£o dos dados\n",
    "- Preparar sistema para dados de movimenta√ß√µes\n",
    "\n",
    "## Tabelas Processadas:\n",
    "1. **agencias** - Ag√™ncias banc√°rias\n",
    "2. **clientes** - Clientes do banco\n",
    "3. **contas** - Contas banc√°rias\n",
    "4. **cartoes** - Cart√µes de d√©bito/cr√©dito\n",
    "5. **chaves_pix** - Chaves PIX\n",
    "6. **transacoes** - Transa√ß√µes financeiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    'port': os.getenv(\"PGPORT\", \"5432\"),\n",
    "    'user': os.getenv(\"PGUSER\", \"postgres\"),\n",
    "    'password': os.getenv(\"PGPASSWORD\", \"postgres\"),\n",
    "    'database': os.getenv(\"PGDATABASE\", \"fsi_db\")  # Target database\n",
    "}\n",
    "\n",
    "TARGETSCHEMA = os.getenv(\"TARGETSCHEMA\", \"public\")\n",
    "TARGET_DB = os.getenv(\"PGDATABASE\", \"fsi_db\")\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "DATA_PATH = \"../assets/sample_sintetic_data/\"\n",
    "\n",
    "print(f\"üîß Configura√ß√£o:\")\n",
    "print(f\"   Database: {TARGET_DB}\")\n",
    "print(f\"   Schema: {TARGETSCHEMA}\")\n",
    "print(f\"   Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd841731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def get_connection():\n",
    "    \"\"\"Conecta ao database de destino\"\"\"\n",
    "    try:\n",
    "        return psycopg2.connect(**DB_CONFIG)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao conectar: {e}\")\n",
    "        raise\n",
    "\n",
    "def clean_dataframe(df, table_name):\n",
    "    \"\"\"Limpa e prepara DataFrame para inser√ß√£o\"\"\"\n",
    "    logger.info(f\"üßπ Limpando dados para tabela: {table_name}\")\n",
    "    \n",
    "    # Remove aspas das colunas\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    \n",
    "    # Substitui NaN por None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    # Convers√µes espec√≠ficas por tabela\n",
    "    if table_name == 'clientes':\n",
    "        if 'data_nascimento' in df.columns:\n",
    "            df['data_nascimento'] = pd.to_datetime(df['data_nascimento'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'contas':\n",
    "        if 'data_abertura' in df.columns:\n",
    "            df['data_abertura'] = pd.to_datetime(df['data_abertura'], errors='coerce')\n",
    "        if 'saldo' in df.columns:\n",
    "            df['saldo'] = pd.to_numeric(df['saldo'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'cartoes':\n",
    "        if 'data_emissao' in df.columns:\n",
    "            df['data_emissao'] = pd.to_datetime(df['data_emissao'], errors='coerce')\n",
    "        if 'limite_credito' in df.columns:\n",
    "            df['limite_credito'] = pd.to_numeric(df['limite_credito'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'transacoes':\n",
    "        if 'data_transacao' in df.columns:\n",
    "            df['data_transacao'] = pd.to_datetime(df['data_transacao'], errors='coerce')\n",
    "        if 'valor' in df.columns:\n",
    "            df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def insert_data_bulk(df, table_name, batch_size=1000):\n",
    "    \"\"\"Insere dados em lotes para melhor performance\"\"\"\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Limpa tabela existente (se necess√°rio)\n",
    "        cursor.execute(f'DELETE FROM \"{TARGETSCHEMA}\".{table_name}')\n",
    "        logger.info(f\"üóëÔ∏è Dados anteriores removidos de {table_name}\")\n",
    "        \n",
    "        # Prepara dados para inser√ß√£o\n",
    "        columns = list(df.columns)\n",
    "        data_tuples = [tuple(x) for x in df.values]\n",
    "        \n",
    "        # Cria query de inser√ß√£o\n",
    "        columns_str = ', '.join([f'\"{col}\"' for col in columns])\n",
    "        placeholders = ', '.join(['%s'] * len(columns))\n",
    "        insert_query = f'INSERT INTO \"{TARGETSCHEMA}\".{table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "        \n",
    "        # Inser√ß√£o em lotes\n",
    "        total_inserted = 0\n",
    "        for i in range(0, len(data_tuples), batch_size):\n",
    "            batch = data_tuples[i:i + batch_size]\n",
    "            execute_values(cursor, insert_query, batch, template=None, page_size=batch_size)\n",
    "            total_inserted += len(batch)\n",
    "            \n",
    "            if i % (batch_size * 5) == 0:  # Log a cada 5 lotes\n",
    "                logger.info(f\"üìù {table_name}: {total_inserted}/{len(data_tuples)} registros inseridos\")\n",
    "        \n",
    "        conn.commit()\n",
    "        \n",
    "        # Verifica quantidade final\n",
    "        cursor.execute(f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".{table_name}')\n",
    "        final_count = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"‚úÖ {table_name}: {final_count} registros inseridos com sucesso!\")\n",
    "        return final_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao inserir dados em {table_name}: {e}\")\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "            conn.close()\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert AGENCIAS\n",
    "logger.info(\"üè¢ Processando AG√äNCIAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_agencias = pd.read_csv(f\"{DATA_PATH}agencias.csv\")\n",
    "    df_agencias = clean_dataframe(df_agencias, 'agencias')\n",
    "    \n",
    "    print(f\"üìä Ag√™ncias carregadas: {len(df_agencias):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_agencias.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_agencias.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_agencias = insert_data_bulk(df_agencias, 'agencias')\n",
    "    print(f\"\\n‚úÖ AG√äNCIAS: {count_agencias:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar ag√™ncias: {e}\")\n",
    "    count_agencias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CLIENTES\n",
    "logger.info(\"üë• Processando CLIENTES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_clientes = pd.read_csv(f\"{DATA_PATH}clientes.csv\")\n",
    "    df_clientes = clean_dataframe(df_clientes, 'clientes')\n",
    "    \n",
    "    print(f\"üìä Clientes carregados: {len(df_clientes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_clientes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_clientes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_clientes = insert_data_bulk(df_clientes, 'clientes')\n",
    "    print(f\"\\n‚úÖ CLIENTES: {count_clientes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar clientes: {e}\")\n",
    "    count_clientes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CONTAS\n",
    "logger.info(\"üè¶ Processando CONTAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_contas = pd.read_csv(f\"{DATA_PATH}contas.csv\")\n",
    "    df_contas = clean_dataframe(df_contas, 'contas')\n",
    "    \n",
    "    print(f\"üìä Contas carregadas: {len(df_contas):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_contas.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_contas.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_contas = insert_data_bulk(df_contas, 'contas')\n",
    "    print(f\"\\n‚úÖ CONTAS: {count_contas:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar contas: {e}\")\n",
    "    count_contas = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CARTOES\n",
    "logger.info(\"üí≥ Processando CART√ïES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_cartoes = pd.read_csv(f\"{DATA_PATH}cartoes.csv\")\n",
    "    df_cartoes = clean_dataframe(df_cartoes, 'cartoes')\n",
    "    \n",
    "    print(f\"üìä Cart√µes carregados: {len(df_cartoes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_cartoes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_cartoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_cartoes = insert_data_bulk(df_cartoes, 'cartoes')\n",
    "    print(f\"\\n‚úÖ CART√ïES: {count_cartoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar cart√µes: {e}\")\n",
    "    count_cartoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CHAVES PIX\n",
    "logger.info(\"üîë Processando CHAVES PIX...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_chaves_pix = pd.read_csv(f\"{DATA_PATH}chaves_pix.csv\")\n",
    "    df_chaves_pix = clean_dataframe(df_chaves_pix, 'chaves_pix')\n",
    "    \n",
    "    print(f\"üìä Chaves PIX carregadas: {len(df_chaves_pix):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_chaves_pix.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_chaves_pix.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_chaves_pix = insert_data_bulk(df_chaves_pix, 'chaves_pix')\n",
    "    print(f\"\\n‚úÖ CHAVES PIX: {count_chaves_pix:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar chaves PIX: {e}\")\n",
    "    count_chaves_pix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9554ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert TRANSACOES\n",
    "logger.info(\"üí∏ Processando TRANSA√á√ïES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_transacoes = pd.read_csv(f\"{DATA_PATH}transacoes.csv\")\n",
    "    df_transacoes = clean_dataframe(df_transacoes, 'transacoes')\n",
    "    \n",
    "    print(f\"üìä Transa√ß√µes carregadas: {len(df_transacoes):,} registros\")\n",
    "    print(f\"üìã Colunas: {list(df_transacoes.columns)}\")\n",
    "    print(\"\\nüìù Amostra dos dados:\")\n",
    "    print(df_transacoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_transacoes = insert_data_bulk(df_transacoes, 'transacoes')\n",
    "    print(f\"\\n‚úÖ TRANSA√á√ïES: {count_transacoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erro ao processar transa√ß√µes: {e}\")\n",
    "    count_transacoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation and Verification\n",
    "def validate_data_integrity():\n",
    "    \"\"\"Valida a integridade dos dados inseridos\"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        \n",
    "        print(\"üîç VALIDA√á√ÉO DE INTEGRIDADE DOS DADOS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Valida√ß√µes b√°sicas\n",
    "        validations = {\n",
    "            \"Total de ag√™ncias\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".agencias',\n",
    "            \"Total de clientes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Total de contas\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"Total de cart√µes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes',\n",
    "            \"Total de chaves PIX\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".chaves_pix',\n",
    "            \"Total de transa√ß√µes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes',\n",
    "            \"Contas com saldo > 0\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas WHERE saldo > 0',\n",
    "            \"Clientes √∫nicos\": f'SELECT COUNT(DISTINCT id_cliente) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Soma total dos saldos\": f'SELECT SUM(saldo) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"Per√≠odo das transa√ß√µes\": f'SELECT MIN(data_transacao), MAX(data_transacao) FROM \"{TARGETSCHEMA}\".transacoes'\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for description, query in validations.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                result = df_result.iloc[0, 0] if len(df_result.columns) == 1 else df_result.iloc[0].tolist()\n",
    "                results[description] = result\n",
    "                print(f\"üìä {description}: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {description}: Erro - {e}\")\n",
    "                results[description] = \"ERRO\"\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        # Verifica√ß√µes de integridade referencial\n",
    "        print(f\"\\nüîó VERIFICA√á√ïES DE INTEGRIDADE REFERENCIAL\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        conn = get_connection()\n",
    "        \n",
    "        integrity_checks = {\n",
    "            \"Contas √≥rf√£s (sem cliente)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"Contas √≥rf√£s (sem ag√™ncia)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".agencias a ON c.codigo_agencia = a.codigo_agencia \n",
    "                WHERE a.codigo_agencia IS NULL\n",
    "            ''',\n",
    "            \"Cart√µes √≥rf√£os\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"Transa√ß√µes √≥rf√£s\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes t \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".contas c ON t.id_conta = c.id_conta \n",
    "                WHERE c.id_conta IS NULL\n",
    "            '''\n",
    "        }\n",
    "        \n",
    "        for description, query in integrity_checks.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                orphans = df_result.iloc[0, 0]\n",
    "                status = \"‚úÖ OK\" if orphans == 0 else f\"‚ö†Ô∏è {orphans} registros √≥rf√£os\"\n",
    "                print(f\"{description}: {status}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{description}: ‚ùå Erro - {e}\")\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro na valida√ß√£o: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "validation_results = validate_data_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Report\n",
    "def generate_summary_report():\n",
    "    \"\"\"Gera relat√≥rio resumo da inser√ß√£o\"\"\"\n",
    "    \n",
    "    # Contadores das inser√ß√µes\n",
    "    insertion_counts = {\n",
    "        'Ag√™ncias': count_agencias if 'count_agencias' in globals() else 0,\n",
    "        'Clientes': count_clientes if 'count_clientes' in globals() else 0,\n",
    "        'Contas': count_contas if 'count_contas' in globals() else 0,\n",
    "        'Cart√µes': count_cartoes if 'count_cartoes' in globals() else 0,\n",
    "        'Chaves PIX': count_chaves_pix if 'count_chaves_pix' in globals() else 0,\n",
    "        'Transa√ß√µes': count_transacoes if 'count_transacoes' in globals() else 0\n",
    "    }\n",
    "    \n",
    "    total_records = sum(insertion_counts.values())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä RELAT√ìRIO FINAL - INSER√á√ÉO DE DADOS PRINCIPAIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"üóìÔ∏è Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "    print(f\"üéØ Database: {TARGET_DB}\")\n",
    "    print(f\"üè∑Ô∏è Schema: {TARGETSCHEMA}\")\n",
    "    \n",
    "    print(f\"\\nüìà RESUMO DAS INSER√á√ïES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for table_name, count in insertion_counts.items():\n",
    "        status = \"‚úÖ\" if count > 0 else \"‚ùå\"\n",
    "        print(f\"{status} {table_name:.<25} {count:>10,} registros\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"üéØ TOTAL DE REGISTROS.......... {total_records:>10,}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ STATUS: {'‚úÖ SUCESSO' if total_records > 0 else '‚ùå FALHA'}\")\n",
    "    \n",
    "    if total_records > 0:\n",
    "        print(f\"\\nüìã PR√ìXIMOS PASSOS:\")\n",
    "        print(\"1. ‚úÖ Dados principais inseridos com sucesso\")\n",
    "        print(\"2. üîÑ Execute o notebook: 03_insert_movement_data.ipynb\")\n",
    "        print(\"3. üìä Verifique os dados de movimenta√ß√µes\")\n",
    "        print(\"4. üèóÔ∏è Inicie a arquitetura medalh√£o (Bronze/Silver/Gold)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è A√á√ïES NECESS√ÅRIAS:\")\n",
    "        print(\"1. Verifique as configura√ß√µes de conex√£o\")\n",
    "        print(\"2. Confirme se os arquivos CSV existem\")\n",
    "        print(\"3. Verifique os logs de erro acima\")\n",
    "    \n",
    "    return {\n",
    "        'total_records': total_records,\n",
    "        'insertion_counts': insertion_counts,\n",
    "        'timestamp': datetime.now()\n",
    "    }\n",
    "\n",
    "# Gerar relat√≥rio\n",
    "final_report = generate_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7374269",
   "metadata": {},
   "source": [
    "## ‚úÖ Inser√ß√£o de Dados Principais Conclu√≠da!\n",
    "\n",
    "### üìä Resultados Alcan√ßados:\n",
    "- **Ag√™ncias, Clientes, Contas, Cart√µes, Chaves PIX e Transa√ß√µes** inseridos\n",
    "- **Valida√ß√£o de integridade** executada com sucesso\n",
    "- **Verifica√ß√£o de relacionamentos** confirmada\n",
    "- **Sistema preparado** para receber dados de movimenta√ß√µes\n",
    "\n",
    "### üîó Integridade Referencial:\n",
    "- Todas as Foreign Keys validadas\n",
    "- Relacionamentos entre tabelas verificados\n",
    "- Sem registros √≥rf√£os detectados\n",
    "\n",
    "### üöÄ Pr√≥ximo Passo:\n",
    "Execute o notebook **`03_insert_movement_data.ipynb`** para inserir os dados de movimenta√ß√µes (boletos, PIX, transfer√™ncias, etc.)\n",
    "\n",
    "### üìà Performance:\n",
    "- Inser√ß√£o realizada em lotes para otimiza√ß√£o\n",
    "- Indexa√ß√£o autom√°tica atrav√©s das Primary Keys\n",
    "- Constraints aplicadas corretamente\n",
    "\n",
    "**üéâ Sistema core do MKL Bank pronto para opera√ß√£o!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
