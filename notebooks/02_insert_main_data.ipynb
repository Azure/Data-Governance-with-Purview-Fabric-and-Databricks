{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b16a13",
   "metadata": {},
   "source": [
    "# InserÃ§Ã£o de Dados Principais - MKL Bank\n",
    "\n",
    "Este notebook insere os dados principais do sistema bancÃ¡rio: agÃªncias, clientes, contas, cartÃµes, chaves PIX e transaÃ§Ãµes.\n",
    "\n",
    "## Objetivo\n",
    "- Carregar e inserir dados das tabelas principais\n",
    "- Validar integridade referencial\n",
    "- Verificar inserÃ§Ã£o dos dados\n",
    "- Preparar sistema para dados de movimentaÃ§Ãµes\n",
    "\n",
    "## Tabelas Processadas:\n",
    "1. **agencias** - AgÃªncias bancÃ¡rias\n",
    "2. **clientes** - Clientes do banco\n",
    "3. **contas** - Contas bancÃ¡rias\n",
    "4. **cartoes** - CartÃµes de dÃ©bito/crÃ©dito\n",
    "5. **chaves_pix** - Chaves PIX\n",
    "6. **transacoes** - TransaÃ§Ãµes financeiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# ConfiguraÃ§Ã£o de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    'port': os.getenv(\"PGPORT\", \"5432\"),\n",
    "    'user': os.getenv(\"PGUSER\", \"postgres\"),\n",
    "    'password': os.getenv(\"PGPASSWORD\", \"postgres\"),\n",
    "    'database': os.getenv(\"PGDATABASE\", \"fsi_db\")  # Target database\n",
    "}\n",
    "\n",
    "TARGETSCHEMA = os.getenv(\"TARGETSCHEMA\", \"public\")\n",
    "TARGET_DB = os.getenv(\"PGDATABASE\", \"fsi_db\")\n",
    "\n",
    "# Caminho para os arquivos CSV\n",
    "DATA_PATH = \"../assets/sample_sintetic_data/\"\n",
    "\n",
    "print(f\"ğŸ”§ ConfiguraÃ§Ã£o:\")\n",
    "print(f\"   Database: {TARGET_DB}\")\n",
    "print(f\"   Schema: {TARGETSCHEMA}\")\n",
    "print(f\"   Data Path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd841731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def get_connection():\n",
    "    \"\"\"Conecta ao database de destino\"\"\"\n",
    "    try:\n",
    "        return psycopg2.connect(**DB_CONFIG)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao conectar: {e}\")\n",
    "        raise\n",
    "\n",
    "def clean_dataframe(df, table_name):\n",
    "    \"\"\"Limpa e prepara DataFrame para inserÃ§Ã£o\"\"\"\n",
    "    logger.info(f\"ğŸ§¹ Limpando dados para tabela: {table_name}\")\n",
    "    \n",
    "    # Remove aspas das colunas\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    \n",
    "    # Substitui NaN por None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    # ConversÃµes especÃ­ficas por tabela\n",
    "    if table_name == 'clientes':\n",
    "        if 'data_nascimento' in df.columns:\n",
    "            df['data_nascimento'] = pd.to_datetime(df['data_nascimento'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'contas':\n",
    "        if 'data_abertura' in df.columns:\n",
    "            df['data_abertura'] = pd.to_datetime(df['data_abertura'], errors='coerce')\n",
    "        if 'saldo' in df.columns:\n",
    "            df['saldo'] = pd.to_numeric(df['saldo'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'cartoes':\n",
    "        if 'data_emissao' in df.columns:\n",
    "            df['data_emissao'] = pd.to_datetime(df['data_emissao'], errors='coerce')\n",
    "        if 'limite_credito' in df.columns:\n",
    "            df['limite_credito'] = pd.to_numeric(df['limite_credito'], errors='coerce')\n",
    "            \n",
    "    elif table_name == 'transacoes':\n",
    "        if 'data_transacao' in df.columns:\n",
    "            df['data_transacao'] = pd.to_datetime(df['data_transacao'], errors='coerce')\n",
    "        if 'valor' in df.columns:\n",
    "            df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def insert_data_bulk(df, table_name, batch_size=1000):\n",
    "    \"\"\"Insere dados em lotes para melhor performance\"\"\"\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Limpa tabela existente (se necessÃ¡rio)\n",
    "        cursor.execute(f'DELETE FROM \"{TARGETSCHEMA}\".{table_name}')\n",
    "        logger.info(f\"ğŸ—‘ï¸ Dados anteriores removidos de {table_name}\")\n",
    "        \n",
    "        # Prepara dados para inserÃ§Ã£o\n",
    "        columns = list(df.columns)\n",
    "        data_tuples = [tuple(x) for x in df.values]\n",
    "        \n",
    "        # Cria query de inserÃ§Ã£o\n",
    "        columns_str = ', '.join([f'\"{col}\"' for col in columns])\n",
    "        placeholders = ', '.join(['%s'] * len(columns))\n",
    "        insert_query = f'INSERT INTO \"{TARGETSCHEMA}\".{table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "        \n",
    "        # InserÃ§Ã£o em lotes\n",
    "        total_inserted = 0\n",
    "        for i in range(0, len(data_tuples), batch_size):\n",
    "            batch = data_tuples[i:i + batch_size]\n",
    "            execute_values(cursor, insert_query, batch, template=None, page_size=batch_size)\n",
    "            total_inserted += len(batch)\n",
    "            \n",
    "            if i % (batch_size * 5) == 0:  # Log a cada 5 lotes\n",
    "                logger.info(f\"ğŸ“ {table_name}: {total_inserted}/{len(data_tuples)} registros inseridos\")\n",
    "        \n",
    "        conn.commit()\n",
    "        \n",
    "        # Verifica quantidade final\n",
    "        cursor.execute(f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".{table_name}')\n",
    "        final_count = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"âœ… {table_name}: {final_count} registros inseridos com sucesso!\")\n",
    "        return final_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ Erro ao inserir dados em {table_name}: {e}\")\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "            conn.close()\n",
    "        raise\n",
    "\n",
    "print(\"âœ… FunÃ§Ãµes auxiliares definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert AGENCIAS\n",
    "logger.info(\"ğŸ¢ Processando AGÃŠNCIAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_agencias = pd.read_csv(f\"{DATA_PATH}agencias.csv\")\n",
    "    df_agencias = clean_dataframe(df_agencias, 'agencias')\n",
    "    \n",
    "    print(f\"ğŸ“Š AgÃªncias carregadas: {len(df_agencias):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_agencias.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_agencias.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_agencias = insert_data_bulk(df_agencias, 'agencias')\n",
    "    print(f\"\\nâœ… AGÃŠNCIAS: {count_agencias:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar agÃªncias: {e}\")\n",
    "    count_agencias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CLIENTES\n",
    "logger.info(\"ğŸ‘¥ Processando CLIENTES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_clientes = pd.read_csv(f\"{DATA_PATH}clientes.csv\")\n",
    "    df_clientes = clean_dataframe(df_clientes, 'clientes')\n",
    "    \n",
    "    print(f\"ğŸ“Š Clientes carregados: {len(df_clientes):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_clientes.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_clientes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_clientes = insert_data_bulk(df_clientes, 'clientes')\n",
    "    print(f\"\\nâœ… CLIENTES: {count_clientes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar clientes: {e}\")\n",
    "    count_clientes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CONTAS\n",
    "logger.info(\"ğŸ¦ Processando CONTAS...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_contas = pd.read_csv(f\"{DATA_PATH}contas.csv\")\n",
    "    df_contas = clean_dataframe(df_contas, 'contas')\n",
    "    \n",
    "    print(f\"ğŸ“Š Contas carregadas: {len(df_contas):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_contas.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_contas.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_contas = insert_data_bulk(df_contas, 'contas')\n",
    "    print(f\"\\nâœ… CONTAS: {count_contas:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar contas: {e}\")\n",
    "    count_contas = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CARTOES\n",
    "logger.info(\"ğŸ’³ Processando CARTÃ•ES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_cartoes = pd.read_csv(f\"{DATA_PATH}cartoes.csv\")\n",
    "    df_cartoes = clean_dataframe(df_cartoes, 'cartoes')\n",
    "    \n",
    "    print(f\"ğŸ“Š CartÃµes carregados: {len(df_cartoes):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_cartoes.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_cartoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_cartoes = insert_data_bulk(df_cartoes, 'cartoes')\n",
    "    print(f\"\\nâœ… CARTÃ•ES: {count_cartoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar cartÃµes: {e}\")\n",
    "    count_cartoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert CHAVES PIX\n",
    "logger.info(\"ğŸ”‘ Processando CHAVES PIX...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_chaves_pix = pd.read_csv(f\"{DATA_PATH}chaves_pix.csv\")\n",
    "    df_chaves_pix = clean_dataframe(df_chaves_pix, 'chaves_pix')\n",
    "    \n",
    "    print(f\"ğŸ“Š Chaves PIX carregadas: {len(df_chaves_pix):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_chaves_pix.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_chaves_pix.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_chaves_pix = insert_data_bulk(df_chaves_pix, 'chaves_pix')\n",
    "    print(f\"\\nâœ… CHAVES PIX: {count_chaves_pix:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar chaves PIX: {e}\")\n",
    "    count_chaves_pix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9554ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Insert TRANSACOES\n",
    "logger.info(\"ğŸ’¸ Processando TRANSAÃ‡Ã•ES...\")\n",
    "\n",
    "try:\n",
    "    # Carregar dados\n",
    "    df_transacoes = pd.read_csv(f\"{DATA_PATH}transacoes.csv\")\n",
    "    df_transacoes = clean_dataframe(df_transacoes, 'transacoes')\n",
    "    \n",
    "    print(f\"ğŸ“Š TransaÃ§Ãµes carregadas: {len(df_transacoes):,} registros\")\n",
    "    print(f\"ğŸ“‹ Colunas: {list(df_transacoes.columns)}\")\n",
    "    print(\"\\nğŸ“ Amostra dos dados:\")\n",
    "    print(df_transacoes.head(3))\n",
    "    \n",
    "    # Inserir dados\n",
    "    count_transacoes = insert_data_bulk(df_transacoes, 'transacoes')\n",
    "    print(f\"\\nâœ… TRANSAÃ‡Ã•ES: {count_transacoes:,} registros inseridos com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"âŒ Erro ao processar transaÃ§Ãµes: {e}\")\n",
    "    count_transacoes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation and Verification\n",
    "def validate_data_integrity():\n",
    "    \"\"\"Valida a integridade dos dados inseridos\"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        \n",
    "        print(\"ğŸ” VALIDAÃ‡ÃƒO DE INTEGRIDADE DOS DADOS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # ValidaÃ§Ãµes bÃ¡sicas\n",
    "        validations = {\n",
    "            \"Total de agÃªncias\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".agencias',\n",
    "            \"Total de clientes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Total de contas\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"Total de cartÃµes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes',\n",
    "            \"Total de chaves PIX\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".chaves_pix',\n",
    "            \"Total de transaÃ§Ãµes\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes',\n",
    "            \"Contas com saldo > 0\": f'SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas WHERE saldo > 0',\n",
    "            \"Clientes Ãºnicos\": f'SELECT COUNT(DISTINCT id_cliente) FROM \"{TARGETSCHEMA}\".clientes',\n",
    "            \"Soma total dos saldos\": f'SELECT SUM(saldo) FROM \"{TARGETSCHEMA}\".contas',\n",
    "            \"PerÃ­odo das transaÃ§Ãµes\": f'SELECT MIN(data_transacao), MAX(data_transacao) FROM \"{TARGETSCHEMA}\".transacoes'\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for description, query in validations.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                result = df_result.iloc[0, 0] if len(df_result.columns) == 1 else df_result.iloc[0].tolist()\n",
    "                results[description] = result\n",
    "                print(f\"ğŸ“Š {description}: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {description}: Erro - {e}\")\n",
    "                results[description] = \"ERRO\"\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        # VerificaÃ§Ãµes de integridade referencial\n",
    "        print(f\"\\nğŸ”— VERIFICAÃ‡Ã•ES DE INTEGRIDADE REFERENCIAL\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        conn = get_connection()\n",
    "        \n",
    "        integrity_checks = {\n",
    "            \"Contas Ã³rfÃ£s (sem cliente)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"Contas Ã³rfÃ£s (sem agÃªncia)\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".contas c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".agencias a ON c.codigo_agencia = a.codigo_agencia \n",
    "                WHERE a.codigo_agencia IS NULL\n",
    "            ''',\n",
    "            \"CartÃµes Ã³rfÃ£os\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".cartoes c \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".clientes cl ON c.id_cliente = cl.id_cliente \n",
    "                WHERE cl.id_cliente IS NULL\n",
    "            ''',\n",
    "            \"TransaÃ§Ãµes Ã³rfÃ£s\": f'''\n",
    "                SELECT COUNT(*) FROM \"{TARGETSCHEMA}\".transacoes t \n",
    "                LEFT JOIN \"{TARGETSCHEMA}\".contas c ON t.id_conta = c.id_conta \n",
    "                WHERE c.id_conta IS NULL\n",
    "            '''\n",
    "        }\n",
    "        \n",
    "        for description, query in integrity_checks.items():\n",
    "            try:\n",
    "                df_result = pd.read_sql_query(query, conn)\n",
    "                orphans = df_result.iloc[0, 0]\n",
    "                status = \"âœ… OK\" if orphans == 0 else f\"âš ï¸ {orphans} registros Ã³rfÃ£os\"\n",
    "                print(f\"{description}: {status}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{description}: âŒ Erro - {e}\")\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ Erro na validaÃ§Ã£o: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Executar validaÃ§Ã£o\n",
    "validation_results = validate_data_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Report\n",
    "def generate_summary_report():\n",
    "    \"\"\"Gera relatÃ³rio resumo da inserÃ§Ã£o\"\"\"\n",
    "    \n",
    "    # Contadores das inserÃ§Ãµes\n",
    "    insertion_counts = {\n",
    "        'AgÃªncias': count_agencias if 'count_agencias' in globals() else 0,\n",
    "        'Clientes': count_clientes if 'count_clientes' in globals() else 0,\n",
    "        'Contas': count_contas if 'count_contas' in globals() else 0,\n",
    "        'CartÃµes': count_cartoes if 'count_cartoes' in globals() else 0,\n",
    "        'Chaves PIX': count_chaves_pix if 'count_chaves_pix' in globals() else 0,\n",
    "        'TransaÃ§Ãµes': count_transacoes if 'count_transacoes' in globals() else 0\n",
    "    }\n",
    "    \n",
    "    total_records = sum(insertion_counts.values())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š RELATÃ“RIO FINAL - INSERÃ‡ÃƒO DE DADOS PRINCIPAIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"ğŸ—“ï¸ Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "    print(f\"ğŸ¯ Database: {TARGET_DB}\")\n",
    "    print(f\"ğŸ·ï¸ Schema: {TARGETSCHEMA}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ RESUMO DAS INSERÃ‡Ã•ES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for table_name, count in insertion_counts.items():\n",
    "        status = \"âœ…\" if count > 0 else \"âŒ\"\n",
    "        print(f\"{status} {table_name:.<25} {count:>10,} registros\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ğŸ¯ TOTAL DE REGISTROS.......... {total_records:>10,}\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ STATUS: {'âœ… SUCESSO' if total_records > 0 else 'âŒ FALHA'}\")\n",
    "    \n",
    "    if total_records > 0:\n",
    "        print(f\"\\nğŸ“‹ PRÃ“XIMOS PASSOS:\")\n",
    "        print(\"1. âœ… Dados principais inseridos com sucesso\")\n",
    "        print(\"2. ğŸ”„ Execute o notebook: 03_insert_movement_data.ipynb\")\n",
    "        print(\"3. ğŸ“Š Verifique os dados de movimentaÃ§Ãµes\")\n",
    "        print(\"4. ğŸ—ï¸ Inicie a arquitetura medalhÃ£o (Bronze/Silver/Gold)\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ AÃ‡Ã•ES NECESSÃRIAS:\")\n",
    "        print(\"1. Verifique as configuraÃ§Ãµes de conexÃ£o\")\n",
    "        print(\"2. Confirme se os arquivos CSV existem\")\n",
    "        print(\"3. Verifique os logs de erro acima\")\n",
    "    \n",
    "    return {\n",
    "        'total_records': total_records,\n",
    "        'insertion_counts': insertion_counts,\n",
    "        'timestamp': datetime.now()\n",
    "    }\n",
    "\n",
    "# Gerar relatÃ³rio\n",
    "final_report = generate_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7374269",
   "metadata": {},
   "source": [
    "## âœ… InserÃ§Ã£o de Dados Principais ConcluÃ­da!\n",
    "\n",
    "### ğŸ“Š Resultados AlcanÃ§ados:\n",
    "- **AgÃªncias, Clientes, Contas, CartÃµes, Chaves PIX e TransaÃ§Ãµes** inseridos\n",
    "- **ValidaÃ§Ã£o de integridade** executada com sucesso\n",
    "- **VerificaÃ§Ã£o de relacionamentos** confirmada\n",
    "- **Sistema preparado** para receber dados de movimentaÃ§Ãµes\n",
    "\n",
    "### ğŸ”— Integridade Referencial:\n",
    "- Todas as Foreign Keys validadas\n",
    "- Relacionamentos entre tabelas verificados\n",
    "- Sem registros Ã³rfÃ£os detectados\n",
    "\n",
    "### ğŸš€ PrÃ³ximo Passo:\n",
    "Execute o notebook **`03_insert_movement_data.ipynb`** para inserir os dados de movimentaÃ§Ãµes (boletos, PIX, transferÃªncias, etc.)\n",
    "\n",
    "### ğŸ“ˆ Performance:\n",
    "- InserÃ§Ã£o realizada em lotes para otimizaÃ§Ã£o\n",
    "- IndexaÃ§Ã£o automÃ¡tica atravÃ©s das Primary Keys\n",
    "- Constraints aplicadas corretamente\n",
    "\n",
    "**ğŸ‰ Sistema core do MKL Bank pronto para operaÃ§Ã£o!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
