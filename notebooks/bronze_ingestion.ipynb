{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "import psycopg2\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "pg_host = \"pgwkpdgsfwsfwvqr.postgres.database.azure.com\"\n",
    "pg_port = \"5432\"\n",
    "pg_db = \"fsi_db\"\n",
    "pg_user = \"pgadmin\"\n",
    "pg_password = \"S7rong!Passw0rd\"\n",
    "pg_schema = \"mkl_bank\"\n",
    "catalog_name = \"mkl_bank\"\n",
    "uc_schema = \"default\"\n",
    "# Azure Storage parameters\n",
    "storage_account_name = \"dlstwkpdgsfwsodgm7j6jy6\"\n",
    "#storage_account_key = dbutils.secrets.get(\"<scope_name>\", \"<key_name>\")\n",
    "container_name = \"bronze\"\n",
    "\n",
    "# Set up the connection to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=pg_host,\n",
    "    port=pg_port,\n",
    "    dbname=pg_db,\n",
    "    user=pg_user,\n",
    "    password=pg_password\n",
    ")\n",
    "\n",
    "# Get the list of tables in the schema\n",
    "cur = conn.cursor()\n",
    "cur.execute(f\"SELECT table_name FROM information_schema.tables WHERE table_schema = '{pg_schema}'\")\n",
    "tables = cur.fetchall()\n",
    "cur.close()\n",
    "\n",
    "# Function to read table from PostgreSQL and write to Azure Storage\n",
    "def ingest_table(table_name: str):\n",
    "    jdbc_url = f\"jdbc:postgresql://{pg_host}:{pg_port}/{pg_db}\"\n",
    "    connection_properties = {\n",
    "        \"user\": pg_user,\n",
    "        \"password\": pg_password,\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "    \n",
    "    df = spark.read.jdbc(url=jdbc_url, table=f\"{pg_schema}.{table_name}\", properties=connection_properties)\n",
    "    \n",
    "    # Write the DataFrame to Azure Storage\n",
    "    #df.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{pg_db}/{pg_schema}/{table_name}\")\n",
    "    # Write the DataFrame to a Unity Catalog managed table\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\n",
    "        f\"{catalog_name}.{uc_schema}.bronze_{table_name}\"\n",
    "    )\n",
    "\n",
    "# Loop through all tables and ingest them\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    ingest_table(table_name)\n",
    "\n",
    "# Close the PostgreSQL connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
